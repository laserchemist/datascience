{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Probability, Randomization and Simulation\n",
    "\n",
    "Welcome to our 2nd Module on statistics and lab 5! This week, we will go over conditionals and iteration, and introduce the concept of randomness. Randomness and probability are central concepts to statistics. Most of this material is covered in [Chapter 8](https://inferentialthinking.com/chapters/09/Randomness.html) of the textbook. Near the end of the lab there are questions on simulation and p-test of the groundhog weather prognostication data. The textbook's Chapter 12 https://inferentialthinking.com/chapters/12/1/AB_Testing.html covers concepts of simulation and p-test.\n",
    "<br>**<center>Learning Goals**\n",
    "|Area|Concept|\n",
    "|---|---|\n",
    "|Booleans|comparison operators |\n",
    "|Conditional|combine booleans with `if` statements to conditionally execute code|\n",
    "|Randomization|use `np.random.choice()` to simulate outcomes|\n",
    "|Iteration|stepping through elements of a list, array, or string sequentially|\n",
    "|Probability|determine the probability of a given outcome, i.e rolling two 6's on a pair of dice|\n",
    "|p-value|statistical test to find probability that outcome is by chance |\n",
    "\n",
    "\n",
    "First, set up the tests and imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "from gofer.ok import check\n",
    "\n",
    "from EDS_mod.EDS_mod import *\n",
    "notebooks = glob.glob('*.ipynb')\n",
    "notebook = max(notebooks, key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, Boolean values can either be `True` or `False`. We get Boolean values when using comparison operators, among which are `<` (less than), `>` (greater than), and `==` (equal to). For a complete list, refer to [Booleans and Comparison](https://inferentialthinking.com/chapters/09/Randomness.html) at the start of Chapter 8.\n",
    "\n",
    "<br>**<center>Boolean Operators**\n",
    "|Operator|Description|Example|\n",
    "|---|---|---|\n",
    "|`==`|test equality| `3 == 3`|\n",
    "|`>`|greater than| `if x > 3:`|\n",
    "|`<`|less than| ` 3 < 5 `|\n",
    "|`>=`| greater than or equal to | `if x >= 5:`|\n",
    "|`<=`| less than or equal to | `if x <= 5:`|\n",
    "|`!=`| not equal to | `if x !=  y:`|\n",
    "\n",
    "\n",
    "\n",
    "Run the cells below to see an example of a comparison operator in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_expression = 3 > 1 + 1\n",
    "bool_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are compatible with comparison operators. The output is an array of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 5, 7, 8, 3, -1]) > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, `True` is also equivalent to the integer 1, and `False` is equivalent to the integer 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_expression == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiation Dose from Airline Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you fly on a commercial aircraft, you are exposed to cosmic radiation from space that is more intense at higher altitudes and at higher latitudes (less atmospheric shielding). The average dose rate is about 0.004 millisieverts (mSv) per hour of flight at cruising altitude (around 10,000 meters or 33,000 feet).\n",
    "\n",
    "Using the function call `np.random.choice(array_name)`, let's simulate a random flight from Philadelphia to a variety of destinations, both near and far. Start by running the cell below several times, and observe how the destinations change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = make_array('Boston', 'Los Angeles', 'London', 'Beijing', 'Sydney')\n",
    "np.random.choice(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(destination, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 1.** </font> \n",
    "Assume we took eight trips at random, and stored the results in an array called `eight_trips`. Find the number trips to London (do not hardcode the answer).  \n",
    "\n",
    "*Hint:* Our solution involves a comparison operator and the `np.count_nonzero` method. This is because Python considers any non-zero integer to be True, and zero to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_destinations = make_array('Los Angeles', 'Boston', 'Sydney', 'Beijing', 'Sydney', 'London', 'Boston', 'London' )\n",
    "number_London = ...\n",
    "number_London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: There is no check here because random.choice will be different every time, but you chould be able to tell by inspection if number_London is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Statements**\n",
    "\n",
    "A conditional statement is made up of many lines that allow Python to choose from different alternatives based on whether some condition is true.\n",
    "\n",
    "Here is a basic example.\n",
    "```python\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 'Positive'\n",
    "```\n",
    "How the function works is if the input `x` is greater than `0`, we get the string `'Positive'` back.\n",
    "\n",
    "If we want to test multiple conditions at once, we use the following general format.\n",
    "\n",
    "```python\n",
    "if <if expression>:\n",
    "    <if body>\n",
    "elif <elif expression 0>:\n",
    "    <elif body 0>\n",
    "elif <elif expression 1>:\n",
    "    <elif body 1>\n",
    "...\n",
    "else:\n",
    "    <else body>\n",
    "```\n",
    "\n",
    "Only one of the bodies will ever be executed. Each `if` and `elif` expression is evaluated and considered in order, starting at the top. As soon as a true value is found, the corresponding body is executed, and the rest of the expression is skipped. If none of the `if` or `elif` expressions are true, then the `else body` is executed. For more examples and explanation, refer to [Section 8.1](https://www.inferentialthinking.com/chapters/08/1/conditional-statements.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 2.** </font> \n",
    "We want to write a function that returns the radiation dose depending on the destination.  The function takes in destination as a string and returns a dose: \n",
    "- 0.004 mSv for Boston (1 hr)\n",
    "- 0.024 mSv for Los Angeles (6 hrs)\n",
    "- 0.028 mSv for London (7 hrs)\n",
    "- 0.052 mSv for Beijing (13 hrs)\n",
    "- 0.08 mSv for Sydney (20 hrs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dose(dest):\n",
    "    if ...\n",
    "        return 0.004\n",
    "    # next condition should return 0.024\n",
    "    ...\n",
    "    # next condition should return 0.028\n",
    "    ...\n",
    "    # next condition should return 0.052\n",
    "    ...\n",
    "    # next condition should return 0.08\n",
    "    ...\n",
    "\n",
    "London_dose = calculate_dose('London')\n",
    "London_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Iteration\n",
    "\n",
    "Using a `for` statement, we can perform a task multiple times. This is known as iteration. Here, we'll simulate drawing different suits from a deck of cards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits = make_array(\"♤\", \"♡\", \"♢\", \"♧\")\n",
    "draws = make_array()\n",
    "repetitions = 6\n",
    "for i in np.arange(repetitions):\n",
    "    draws = np.append(draws, np.random.choice(suits))\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use of iteration is to loop through a set of values. For instance, we can print out all of the colors of the rainbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow = make_array(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\")\n",
    "for color in rainbow:\n",
    "    print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indented part of the `for` loop, known as the body, is executed once for each item in `rainbow`. Note that the name `color` is arbitrary; we could easily have named it something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 3.** </font>  \n",
    "You're a pilot for Random Air and you fly between Philadelphia one of these destinations 60 times in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = make_array('Boston', 'Los Angeles', 'London', 'Beijing', 'Sydney')\n",
    "num_trips = 60\n",
    "\n",
    "total_dose = ... # Initialize the value of total *before* you start the loop\n",
    "\n",
    "for ... in ...: # Create a loop over the number of trips\n",
    "    dest = ... # Select a destination at random from your array\n",
    "    dose = ...  # Use your dose function to determine the radiation dose received on the flight\n",
    "    ...         # Add the dose to your running total\n",
    "\n",
    "total_dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A normal background radiation dose for the average person is 2.4 mSv/year from natural sources. Pilots and flight crews typically receive an additional 2-5 mSv/yr, or about twice background. So, a pilot’s excess annual dose is above the general public’s recommended limit, but well below occupational limits for radiation workers. There’s no evidence of significant health risk at these levels, but it’s a unique occupational exposure. This is one of the few jobs where you can get more radiation than a nuclear power plant worker. Few of the rest of us fly anywhere close to this number of hours annually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 4.** </font> \n",
    "Charles Darwin is a famous naturalist and biologist from the late 1800s.  While Darwin is known for several different theories, one of his most well known theory involved the finches on Galapagos Islands and helped form his theory on natural selection and speciation.  In this question, we are going to loop through Charles Darwin's book on the Origin of Species and count up the number of times he refers to bird or birds in the text.\n",
    "\n",
    "*Hint:* We want to count all instances of bird, birds, Bird and Birds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_string = open('darwin_origin_species.txt', encoding='utf-8').read()\n",
    "darwin_words = np.array(darwin_string.split())\n",
    "\n",
    "birds = ...\n",
    "...\n",
    "\n",
    "\n",
    "birds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomers have their telescope pointed towards a particular section of sky.  During an hour period, astronomers have 0.7 chance of seeing a Meteoroid in the sky. \n",
    "\n",
    "### <font color=blue> **Question 5.** </font> \n",
    "What is the probability that the astronomer will not see a Meteoroid in this hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meteoroid = ...\n",
    "no_meteoroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 6.** </font> \n",
    "What is the probability of seeing a meteoroid in the first hour and then seeing a meteoroid in the second hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_meteoroids = ...\n",
    "two_meteoroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 6 Discussion.** </font>\n",
    "We are assuming here that the probabilities are \"unconditional.\" That is that the probability of seeing a meteoroid in the second hour does not depend on whether or not you saw one in the first hour. Not all probabilities are unconditional. **Create a markdown cell below this one and describe an instance of conditional probability, and explain why the odds change depending on the previous outcome.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to save your notebook before running this check.\n",
    "check('tests/q6_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 7.** </font> \n",
    "A club on campus is holding a contest.  There is a bag with two red marbles, two green marbles, and two blue marbles. You have to draw three marbles separately. In order to win, all three of these marbles must be of different colors.  What is the probability of you winning the contest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_prob = ...\n",
    "winning_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application:  Groundhog's Day\n",
    "\n",
    "Researchers seek to understand whether Groundhogs are able to predict the onset of spring any better than chance.  In this particular study, researchers look at 33 groundhogs across North America (USA and Canada) and gather data for several years.  This includes whether the groundhog saw its shadow and whether the onset of spring was late or early - which for our uses are going to be the two columns we're going to focus on.  In the cell below, we read in dataset into a table called `groundhogdata`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groundhogdata = Table.read_table('GroundHogData/summarizedGroundhogData_20210326.csv')\n",
    "groundhogdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each groundhog has the options of either seeing their shadow or not seeing their shadow.  If the groundhog sees their shadow, they are then predicting that spring will come late.  If a groundhog doesn't see their shadow, then they are predicting that spring will come early. We are trying to see if the groundhog has special perception and can predict the onset of Spring better  than a coin toss (50/50).\n",
    "\n",
    "### <font color=blue> **Question 8.** </font>\n",
    "Create a table that contains all the rows where the Groundhogs correctly predicted the onset of Spring. Since there are two ways the groundhogs could be correct, you may want to make multiple tables and then combine them. \n",
    "\n",
    "*Hint:* You can combine tables with the same columns using the append() method. [See the documentation.](https://www.data8.org/datascience/_autosummary/datascience.tables.Table.append.html#datascience.tables.Table.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_late = groundhogdata.where('shadowPres',  ...).where(..., ...)\n",
    "no_early = ...\n",
    "\n",
    "correct_tbl = ...\n",
    "correct_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 9.** </font>\n",
    "Calculate the percent of time that the groundhogs correctly identified the onset of Spring. Hint: It should be the number of the correct predictions divided by the number of total predictions. Try the table method .num_rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = .../...*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q9.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how often groundhogs across North America correctly identify the onset of spring, we want to simulate groundhog data to see if the groundhogs do better than random.  \n",
    "\n",
    "### <font color=blue> **Question 10.** </font>\n",
    "Let's set up the needed options and iterations.  Set the possible options for whether the groundhog sees shadows and the spring onset.  Set num_observations to the total number of groundhog observations from the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_options = np.array(['yes', 'no'])\n",
    "spring_options = ...\n",
    "num_observations = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q10.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 11.** </font>\n",
    "Now let's set up the simulation. For each of the observations, randomly choose whether the groundhog sees their shadow and then randomly choose when spring starts.  Depending on the random choices, we can use conditional statements to either record the choice as right or wrong by adding one to `right` or `wrong` variables (increment).  Use concepts in Questions 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0 # Initialize at zero \n",
    "wrong = ...\n",
    "# Iteration\n",
    "for obs in np.arange(...):\n",
    "    shadow = np.random.choice(shadow_options)\n",
    "    spring = ...\n",
    "    # Now decide of simulated groundhog is right or wrong\n",
    "    if shadow == 'yes' and spring == 'late':\n",
    "        ...\n",
    "    elif  ...          and   ...           :\n",
    "        ...\n",
    "    else:\n",
    "        ...\n",
    "    \n",
    "# Calculate the fraction of simulated correct answers\n",
    "simulated_frac_correct = ...\n",
    "simulated_frac_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q11.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 12.** </font> \n",
    "In the markdown cell below, compare the results of your simulation in question 11 and the actual number of correctly identified spring onsets by the groundhogs in the study. <font color='green'>Does the Groundhog have true insights into the upcoming weather and timing of Spring or would a coin toss at the 50 yard line of the field at the Linc do just as well at predicting Spring's onset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to save your notebook before running this check.\n",
    "check('tests/q12_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 13.** </font> \n",
    "Now we can test if the Groundhog's prediction is statistically significant by calculating a \"p-value,\" where 'p' stands for probability. The p-value is the probability that the result is simply the same as chance or as if the Groundhog randomly guessed an answer. \n",
    "\n",
    "**Null Hypothesis:** Groundhog predictions are no better than random guessing.<br>\n",
    "**Alternative Hypothesis:** Groundhog predictions are better than random.\n",
    "\n",
    "We can only reject the null hypothesis and put faith in groundhog predictions if the p-value, is small. How small? This depends on how confident you need to be to consider a result to be \"statistically significant.\" Typically, if there is a less than 5% of getting the result randomly (p-value < 0.05) we say the result merits further study, and if the odds are less than 1% (p-value < 0.01) we may be on to something real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the odds of getting the result randomly, we have to repeat the simulation many times because one simulation could simply generate a surprisingly good set of observations but many repeats will give us the sense of the true probability of a random guess yielding a correct prediction. To make the function more general we will replace the `num_observations` with `observations` so we can look at subsets of ground hogs and compare their accuracies given fewer observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_ground(repeats,observations):\n",
    "    correct_obs = []\n",
    "    for i in np.arange(repeats):\n",
    "        right = 0 \n",
    "        wrong = ...\n",
    "        for obs in np.arange(observations):\n",
    "            shadow = np.random.choice(shadow_options)\n",
    "            spring = ...\n",
    "            if shadow == 'yes' and spring == 'late':\n",
    "                ...\n",
    "            elif ...           and                 :\n",
    "                ...\n",
    "            else:\n",
    "                ...\n",
    "        simulated_frac_correct = right / observations\n",
    "        correct_obs.append(simulated_frac_correct)\n",
    "    return correct_obs        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the average for one set of random guesses we get the below figure which will vary each time we run the simulation.\n",
    "Compare two simulations by running them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Simulation #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_ground(1,num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Simulation #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_ground(1,num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='blue'>Use this cell to compare simulation #1 with #2.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will simulate 1000 repeats and compare them to our Groundhogs' observation to ultimately get the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "plt.hist(sim_ground(num_simulations, num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = Table().with_columns(\"Correct\",sim_ground(num_simulations, num_observations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = ... # answer from Question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\", bins=np.arange(0.4,0.6,.01))\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p value\n",
    "The p value is the proportion of the randomly generated results which are better than the observation we are examining. In this case, the observation we are 'testing' is the collected Groundhog prediction accuracy, `percent_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_All = np.count_nonzero(hogsimdata.column('Correct') >= percent_correct/100) / num_simulations\n",
    "p_All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Groundhogs' collective observations are the same or worse than chance `p_value`*100% of the time which is larger than 5% so statistically cannot reject the null hypothesis that the Groundhog's observations are not better than chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essex Ed (EE)\n",
    "Essex Ed seems to be a far better prognosticator than our group of Groundhogs. Let's see if Essex Ed's predictions are better than chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE_data = groundhogdata.where('hogID', \"...\")\n",
    "EE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE_correct = correct_tbl.where('hogID', \"...\")\n",
    "EE_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need a new simulation Table because Essex Ed only has 9 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE_observations = groundhogdata.where('hogID', \"EE\").num_rows\n",
    "EE_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = Table().with_columns(\"Correct\", sim_ground(num_simulations, EE_observations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to the method used in Question 9\n",
    "# You need to use the number of rows in EE_correct and EE_data\n",
    "percent_correct = ... \n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\", bins=20)\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute Essex Ed's p-value, see `p_All` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_EE = ...\n",
    "p_EE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Is Essex Ed a better predictor than chance? Why or why not given the above p-value? Answer in the below markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to save your notebook before running this check.\n",
    "check('tests/q13a_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punxsutawney Phil (PYPL)\n",
    "Let's see how our local hero, Punxsutawney Phil, does at predicting relative to chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogdata.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tbl.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percent_correct = ... # Refer to the method used in Question 9 with .num_rows of each Table directly above\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need a new simulation Table because Punxsutawney Phil only has 107 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYPL_observations = ...\n",
    "PYPL_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = ...\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\",bins=20)\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute Punxsutawney Phils's p-value, see `p_EE` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_PYPL = ...\n",
    "p_PYPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Is Punxsutawney Phil a better predictor than chance? Why or why not given the above p-value? Answer in the below markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to save your notebook before running this check.\n",
    "check('tests/q13b_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 14.** </font>\n",
    "\n",
    "At the end of each lab, please include a reflection. \n",
    "* How did this lab go? \n",
    "* What aspects of this introduction to probability do you find confusing?\n",
    "* Were there questions you found especially challenging you would like your instructor to review in class? \n",
    "* How long did the lab take you to complete?\n",
    "\n",
    "Share your feedback so we can continue to improve this class!\n",
    "\n",
    "**Insert a markdown cell below this one and write your reflection on this lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BE SURE TO SAVE YOUR NOTEBOOK BEFORE RUNNING THIS TEST\n",
    "check(\"tests/q14_open_ended.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "questions = [\"2\",\"3\", \"4\", \"5\", \"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\n",
    "             \"12_open_ended\", \"13a_open_ended\",\"13b_open_ended\",\"14_open_ended\"]\n",
    "for x in questions:\n",
    "    print(\"Testing question {}: \".format(x))\n",
    "    display(check(\"tests/q{}.py\".format(x)))\n",
    "    score = check('tests/q{}.py'.format(str(x)))\n",
    "    if score.grade == 1.0:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_correct = correct/len(questions)*100\n",
    "if perc_correct < 80:\n",
    "    msg = 'look over your work again, seek help, some errors!!!'\n",
    "else:\n",
    "    msg = 'nice work!'\n",
    "print(f\"----\\n{name} {msg}\\n----\\nusername: {user}\")\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)\n",
    "print(f'Score: {correct/len(questions)*100:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
