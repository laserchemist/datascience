{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Probability, Randomization and Simulation\n",
    "\n",
    "Welcome to our 2nd Module on statistics and lab 5! This week, we will go over conditionals and iteration, and introduce the concept of randomness. Randomness and probability are central concepts to statistics. Most of this material is covered in [Chapter 8](https://inferentialthinking.com/chapters/09/Randomness.html) of the textbook. Near the end of the lab there are questions on simulation and p-Test of the groundhog weather prognostication data. The textbook's Chapter 12 https://inferentialthinking.com/chapters/12/1/AB_Testing.html covers concepts of simulation and p-test.\n",
    "<br>**<center>Learning Goals**\n",
    "|Area|Concept|\n",
    "|---|---|\n",
    "|Booleans|comparison operators |\n",
    "|Conditional|combine booleans with `if` statements to conditionally execute code|\n",
    "|Randomization|use `np.random.choice()` to simulate outcomes|\n",
    "|Iteration|stepping through elements of a list, array, or string sequentially|\n",
    "|Probability|determine the probability of a given outcome, i.e rolling two 6's on a pair of dice|\n",
    "|p-value|statistical test to find probability that outcome is by chance |\n",
    "\n",
    "\n",
    "First, set up the tests and imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, Boolean values can either be `True` or `False`. We get Boolean values when using comparison operators, among which are `<` (less than), `>` (greater than), and `==` (equal to). For a complete list, refer to [Booleans and Comparison](https://inferentialthinking.com/chapters/09/Randomness.html) at the start of Chapter 8.\n",
    "\n",
    "<br>**<center>Boolean Operators**\n",
    "|Operator|Description|Example|\n",
    "|---|---|---|\n",
    "|`==`|test equality| `3 == 3`|\n",
    "|`>`|greater than| `if x > 3:`|\n",
    "|`<`|less than| ` 3 < 5 `|\n",
    "|`>=`| greater than or equal to | `if x >= 5:`|\n",
    "|`<=`| less than or equal to | `if x <= 5:`|\n",
    "|`!=`| not equal to | `if x !=  y:`|\n",
    "\n",
    "\n",
    "\n",
    "Run the cells below to see an example of a comparison operator in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_expression = 3 > 1 + 1\n",
    "bool_expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are compatible with comparison operators. The output is an array of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 5, 7, 8, 3, -1]) > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, `True` is also equivalent to the integer 1, and `False` is equivalent to the integer 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_expression == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pizza Time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're hanging out with friends and ordered pizza.  You have a stack of pizza boxes that include plain cheese, veggie, supreme, and pepperoni.  \n",
    "\n",
    "Using the function call `np.random.choice(array_name)`, let's simulate opening a pizza box at random. Start by running the cell below several times, and observe how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizza = make_array('cheese', 'veggie', 'supreme', 'pepperoni')\n",
    "np.random.choice(pizza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 1.** </font> \n",
    "Assume we took 7 slices of pizza at random, and stored the results in an array called `seven_slices`. Find the number of slices of pepperoni pizza (do not hardcode the answer).  \n",
    "\n",
    "*Hint:* Our solution involves a comparison operator and the `np.count_nonzero` method. This is because Python considers any non-zero integer to be True, and zero to be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_slices = make_array('cheese', 'supreme', 'cheese', 'pepperoni', 'veggie', 'veggie', 'cheese')\n",
    "number_pepperoni = ...\n",
    "number_pepperoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Statements**\n",
    "\n",
    "A conditional statement is made up of many lines that allow Python to choose from different alternatives based on whether some condition is true.\n",
    "\n",
    "Here is a basic example.\n",
    "```python\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 'Positive'\n",
    "```\n",
    "How the function works is if the input `x` is greater than `0`, we get the string `'Positive'` back.\n",
    "\n",
    "If we want to test multiple conditions at once, we use the following general format.\n",
    "\n",
    "```python\n",
    "if <if expression>:\n",
    "    <if body>\n",
    "elif <elif expression 0>:\n",
    "    <elif body 0>\n",
    "elif <elif expression 1>:\n",
    "    <elif body 1>\n",
    "...\n",
    "else:\n",
    "    <else body>\n",
    "```\n",
    "\n",
    "Only one of the bodies will ever be executed. Each `if` and `elif` expression is evaluated and considered in order, starting at the top. As soon as a true value is found, the corresponding body is executed, and the rest of the expression is skipped. If none of the `if` or `elif` expressions are true, then the `else body` is executed. For more examples and explanation, refer to [Section 8.1](https://www.inferentialthinking.com/chapters/08/1/conditional-statements.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 2.** </font> \n",
    "We want to write a function that returns the price of a pizza depending on the type.  The function takes in the type of pizza as a string and returns a price: 10 dollars for cheese,  12 dollars for veggie, 13 dollars for pepperoni, and 15 dollars for supreme.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pizza_price(pizza):\n",
    "    if ...\n",
    "        return 10\n",
    "    # next condition should return 12\n",
    "    ...\n",
    "    # next condition should return 13\n",
    "    ...\n",
    "    # next condition should return 15\n",
    "    ...\n",
    "\n",
    "plain_price = pizza_price('cheese')\n",
    "plain_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Iteration\n",
    "\n",
    "Using a `for` statement, we can perform a task multiple times. This is known as iteration. Here, we'll simulate drawing different suits from a deck of cards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits = make_array(\"♤\", \"♡\", \"♢\", \"♧\")\n",
    "draws = make_array()\n",
    "repetitions = 6\n",
    "for i in np.arange(repetitions):\n",
    "    draws = np.append(draws, np.random.choice(suits))\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use of iteration is to loop through a set of values. For instance, we can print out all of the colors of the rainbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow = make_array(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\")\n",
    "for color in rainbow:\n",
    "    print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indented part of the `for` loop, known as the body, is executed once for each item in `rainbow`. Note that the name `color` is arbitrary; we could easily have named it something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 3.** </font>  \n",
    "You're working at a pizza shop, and we want to simulate the amount of money the shop brings in over two weeks (the shop sells 500 pizzas a week on average).  Write code that simulates the total money made after 2 weeks using your `pizza_price` function above assuming orders for the different pizza types are equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_pizzas = ... # make an array of pizza types\n",
    "pizzas = 1000\n",
    "\n",
    "total_money = ... # Initialize the value of total *before* you start the loop\n",
    "\n",
    "for ... in ...: # Create a loop over the 1000 pizzas\n",
    "    pizza = ... # Select a pizza type at random from your array\n",
    "    cost = ...  # Use your function to determine its cost\n",
    "    ...         # Add the cost to your running total\n",
    "\n",
    "total_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 4.** </font> \n",
    "Charles Darwin is a famous naturalist and biologist from the late 1800s.  While Darwin is known for several different theories, one of his most well known theory involved the finches on Galapagos Islands and helped form his theory on natural selection and speciation.  In this question, we are going to loop through Charles Darwin's book on the Origin of Species and count up the number of times he refers to bird or birds in the text.\n",
    "\n",
    "*Hint:* We want to count all instances of bird, birds, Bird and Birds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_string = open('darwin_origin_species.txt', encoding='utf-8').read()\n",
    "darwin_words = np.array(darwin_string.split())\n",
    "\n",
    "birds = ...\n",
    "...\n",
    "\n",
    "\n",
    "birds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "darwin_string = open('darwin_origin_species.txt', encoding='utf-8').read()\n",
    "darwin_words = np.array(darwin_string.split())\n",
    "len(darwin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomers have their telescope pointed towards a particular section of sky.  During an hour period, astronomers have 0.7 chance of seeing a Meteoroid in the sky. \n",
    "\n",
    "### <font color=blue> **Question 5.** </font> \n",
    "What is the probability that the astronomer will not see a Meteoroid in this hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meteoroid = ...\n",
    "no_meteoroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 6.** </font> \n",
    "What is the probability of seeing a meteroid in the first hour and then seeing a meteoroid in the second hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_meteoroids = ...\n",
    "two_meteoroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 6 Discussion.** </font>\n",
    "We are assuming here that the probabilities are \"unconditional.\" That is that the probability of seeing a meteoroid in the second hour does not depend on whether or not you saw one in the first hour. Not all probabilities are unconditional. **Create a markdown cell below this one and describe an instance of conditional probability, and explain why the odds change depending on the previous outcome.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 7.** </font> \n",
    "A club on campus is holding a contest.  There is a bag with two red marbles, two green marbles, and two blue marbles. You have to draw three marbles separately. In order to win, all three of these marbles must be of different colors.  What is the probability of you winning the contest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_prob = ...\n",
    "winning_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application:  Groundhog's Day\n",
    "\n",
    "Researchers seek to understand whether Groundhogs are able to predict the onset of spring any better than chance.  In this particular study, researchers look at 33 groundhogs across North America (USA and Canada) and gather data for several years.  This includes whether the groundhog saw its shadow and whether the onset of spring was late or early - which for our uses are going to be the two columns we're going to focus on.  In the cell below, we read in dataset into a table called `groundhogdata`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groundhogdata = Table.read_table('GroundHogData/summarizedGroundhogData_20210326.csv')\n",
    "groundhogdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each groundhog has the options of either seeing their shadow or not seeing their shadow.  If the groundhog sees their shadow, they are then predicting that spring will come late.  If a groundhog doesn't see their shadow, then they are predicting that spring will come early. We are trying to see if the groundhog has special perception and can predict the onset of Spring better  than a coin toss (50/50).\n",
    "\n",
    "### <font color=blue> **Question 8.** </font>\n",
    "Create a table that contains all the rows where the Groundhogs correctly predicted the onset of Spring. Since there are two ways the groundhogs could be correct, you may want to make multiple tables and then combine them. \n",
    "\n",
    "*Hint:* You can combine tables with the same columns using the append() method. [See the documentation.](https://www.data8.org/datascience/_autosummary/datascience.tables.Table.append.html#datascience.tables.Table.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_late = groundhogdata.where('shadowPres',  ...).where(..., ...)\n",
    "no_early = ...\n",
    "\n",
    "correct_tbl = ...\n",
    "correct_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 9.** </font>\n",
    "Calculate the percent of time that the groundhogs correctly identified the onset of Spring. Hint: It should be the number of the correct predictions devided by the number of total predictions. Try the table method .num_rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = .../...*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q9.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how often groundhogs across North America correctly identify the onset of spring, we want to simulate groundhog data to see if the groundhogs do better than random.  \n",
    "\n",
    "### <font color=blue> **Question 10.** </font>\n",
    "Let's set up the needed options and iterations.  Set the possible options for whether the groundhog sees shadows and the spring onset.  Set num_observations to the total number of groundhog observations from the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_options = np.array(['yes', 'no'])\n",
    "spring_options = ...\n",
    "num_observations = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q10.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 11.** </font>\n",
    "Now let's set up the simulation. For each of the observations, random choose whether the groundhog sees their shadow and then randomly choose when spring starts.  Depending on the random choices, we can use conditional statements to either record the choice as right or wrong by adding one to `right` or `wrong` variables (increment).  Use concepts in Questions 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0 # Initialize at zero \n",
    "wrong = ...\n",
    "# Iteration\n",
    "for obs in np.arange(...):\n",
    "    shadow = np.random.choice(shadow_options)\n",
    "    spring = ...\n",
    "    # Now decide of silicon groundhog is right or wrong\n",
    "    if shadow == 'yes' and spring == 'late':\n",
    "        ...\n",
    "    elif  ...          and   ...           :\n",
    "        ...\n",
    "    else:\n",
    "        ...\n",
    "    \n",
    "# Calculate the fraction of simulated correct answers\n",
    "simulated_frac_correct = ...\n",
    "simulated_frac_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q11.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 12.** </font> \n",
    "In the markdown cell below, compare the results of your simulation in question 11 and the actual number of correctly identified spring onsets by the groundhogs in the study. <font color='green'>Does the Groundhog have true insights into the upcoming weather and timing of Spring or would a coin toss at the 50 yard line of the field at the Linc do just as well at predicting Spring's onset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='blue'>Use this cell to write your answer to question 12.</font>\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 13.** </font> \n",
    "Now we can test if the Groundhog's prediction is statistically significant using a test known as the p-test. 'p' stands for probability which is the probability that the result is simply the same as chance or as if the Groundhog randomly guessed an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to repeat the simulation many times because one simulation could simply generate a surpisingly good set of observations but many repeats will give us the sense of the true probability of a random guess yielding a correct prediction. To make the function more general we will replace the `num_observations` with `observations` so we can look at subsets of ground hogs and compare their accuracies given fewer observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_ground(repeats,observations):\n",
    "    correct_obs = []\n",
    "    for i in np.arange(repeats):\n",
    "        right = 0 \n",
    "        wrong = ...\n",
    "        for obs in np.arange(observations):\n",
    "            shadow = np.random.choice(shadow_options)\n",
    "            spring = ...\n",
    "            if shadow == 'yes' and spring == 'late':\n",
    "                ...\n",
    "            elif ...           and                 :\n",
    "                ...\n",
    "            else:\n",
    "                ...\n",
    "        simulated_frac_correct = right / observations\n",
    "        correct_obs.append(simulated_frac_correct)\n",
    "    return correct_obs        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the average for one set of random guesses we get the below figure which will vary each time we run the simulation.\n",
    "Compare two simulations by running them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Simulation #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_ground(1,num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Simulation #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_ground(1,num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='blue'>Use this cell to compare simulation #1 with #2.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will simulate 1000 repeats and compare them to our Groundhogs' observation to ultimamtely get the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_ground(1000, num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.xlabel('simulated_frac_correct')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = Table().with_columns(\"Correct\",sim_ground(1500, num_observations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = ... # answer from Question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\", bins=np.arange(0.4,0.6,.01))\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p value\n",
    "The p value is the proportion of the randomly generated results which are better than the observation we are examining. In this case, the observation we are 'testing' is the collected Groundhog prediction accuracy, `percent_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_All = np.count_nonzero(hogsimdata.column('Correct') >= percent_correct/100) / 1500\n",
    "p_All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Groundhogs' collective observations are the same or worse than chance `p_value`*100% of the time which is larger than 5% so statistically we would often accept the hypothesis that the Groundhog's observations are not better than chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essex Ed (EE)\n",
    "Essex Ed seems to be a far better prognosticator then our group of Groundhogs. Let's see if Essex Ed's prediction are better than chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogdata.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tbl.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need a new simulation Table because Essex Ed only has 9 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE_observations = groundhogdata.where('hogID',\"EE\").num_rows\n",
    "EE_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = Table().with_columns(\"Correct\",sim_ground(1500,EE_observations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = ... # Refer to the method used in Question 9\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\",bins=20)\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute Essex Ed's p-value, see `p_All` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_EE = ...\n",
    "p_EE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Is Essex Ed a better predictor then chance? Why or why not given the above p-value? Answer in the below markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punxsutawney Phil (PYPL)\n",
    "Let's see how our local hero, Punxsutawney Phil, does at predicting relative to chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogdata.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tbl.where('hogID',\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percent_correct = ... # Refer to the method used in Question 9 with .num_rows of each Table directly above\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need a new simulation Table because Punxsutawney Phil only has 107 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYPL_observations = ...\n",
    "PYPL_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata = ...\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(\"Correct\",bins=20)\n",
    "plt.scatter(percent_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute Punxsutawney Phils's p-value, see `p_EE` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_PYPL = ...\n",
    "p_PYPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Is Punxsutawney Phil a better predictor then chance? Why or why not given the above p-value? Answer in the below markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 14.** </font>\n",
    "\n",
    "At the end of each lab, please include a reflection. \n",
    "* How did this lab go? \n",
    "* What aspects of this introduction to probability do you find confusing?\n",
    "* Were there questions you found especially challenging you would like your instructor to review in class? \n",
    "* How long did the lab take you to complete?\n",
    "\n",
    "Share your feedback so we can continue to improve this class!\n",
    "\n",
    "**Insert a markdown cell below this one and write your reflection on this lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "total = 11\n",
    "for x in range(1, total+1):\n",
    "    print('Testing question {}: '.format(str(x)))\n",
    "    g = check('tests/q{}.py'.format(str(x)))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Nice work \",name, user)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
