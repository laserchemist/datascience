{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47517f09-8e9c-493a-927c-c54cad1c9f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132e5f2-26f4-4db2-b313-dff055c44cc5",
   "metadata": {},
   "source": [
    "# Data Munging\n",
    "\n",
    "\"Data munging is a set of concepts and a methodology for taking data from unusable and erroneous forms to the new levels of structure and quality required by modern analytics processes and consumers.\" [Ref](https://www.talend.com/resources/what-is-data-munging/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bb7de-6ec8-4fd2-93d3-6900b2d8bbe1",
   "metadata": {},
   "source": [
    "## Dealing with missing data\n",
    "\n",
    "Often dataset have missing values, which when loaded into python can result in nan's (Not A Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64abd0-8389-4edb-ad03-b3ff4a1abbd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ramen = Table().read_table(\"data/ramen-ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025d1e7-0197-4cf6-a38d-4f3eee1fcc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ramen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79254fd-0365-4319-8773-98ad436f29ef",
   "metadata": {},
   "source": [
    "If you look at the CSV file, you will see that the column \"Top Ten\" only has ten entries; the rest of the column values are blank. Although it appears that there is also at least one entry with just a carriage return ('\\n')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf9723-b6bc-4bf6-bd7a-2ed664da6a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print all the unique entries in the column\n",
    "np.unique(ramen.column(\"Top Ten\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9754cf9-6544-4807-9d57-ef9657d0ab63",
   "metadata": {},
   "source": [
    "**Important point:** These are not true numpy nans, but just the string 'nan' so we can find and replace them with the where command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358bae9-0eab-456b-902d-02ef73759018",
   "metadata": {},
   "source": [
    "Suppose we want to replace all of the lines that have nans or '\\n' with the string \"Not in top 10\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072babd2-5afb-4ff5-8611-ed2321d84cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a function that accepts a single value\n",
    "def replace_nan(x):\n",
    "    if x == 'nan':\n",
    "        return \"Not in top 10\"\n",
    "    elif x == '\\n':\n",
    "        return \"Not in top 10\"\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e1293-39be-442d-8f19-d30375c5e537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use our function to replace values in the Top Ten column using apply()\n",
    "ramen = ramen.with_column('Top Ten', ramen.apply(replace_nan, 'Top Ten') )\n",
    "ramen.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a99b9-3435-4f0a-be1b-b0c4fbf28334",
   "metadata": {},
   "source": [
    "**Mission Accomplished!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c027f-8053-4c4e-9d20-974618432574",
   "metadata": {},
   "source": [
    "### What if we have true np.nan values in our data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61302293-219d-4109-ad71-fbf35c1b50f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load one of the candidate group project data sets. This one is about air quality.\n",
    "url = \"https://opendata.arcgis.com/api/v3/datasets/3899a065577747fbb824f0a21afc2e7c_0/downloads/data?format=csv&spatialRefId=4326\"\n",
    "air = Table.read_table(url)\n",
    "air.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12def9f6-20a1-4ddf-9c8d-7651dd84bbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ozone_values = np.unique(air.column('OZONE_PPM'))\n",
    "ozone_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf61fbf-48d4-40d5-b348-a235f5319038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(ozone_values[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5001bc-4fe4-44b4-9d5f-7ad45c345802",
   "metadata": {},
   "source": [
    "Yup! That is a true nan value. We cannot remove these with the where() method because Equality doesn't work for nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acfe6d-94eb-493b-a446-906728c238dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f14fc71-e8ba-42ec-a0e9-07c9668c1807",
   "metadata": {},
   "source": [
    "Wow! That is confusing. It turns out you cannot test for equality with nans, but you can identify them. Numpy has a method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708ec3e-cef2-491f-b5b4-2b86521137e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = make_array( 5, 8, 12, np.nan, 2, 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f3112-15f6-48e0-9464-29474f8ee653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c3174-f709-426c-a604-64b69fe964f7",
   "metadata": {},
   "source": [
    "We can use this to replace the nans in our data table. Let's say we wanted to replace all the OZONE_PPM values that are nan with zeros. How do we do this? Again, we can start by writing a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d31cc-1ccf-4a4d-b19d-c63add1e2c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a function that accepts a single value\n",
    "def replace_true_nan(x):\n",
    "    if np.isnan(x):\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a7004-0a3e-47e4-9ec2-ef0e2cde5921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function\n",
    "for x in test:\n",
    "    print(replace_true_nan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb5b94-9c16-4f30-bb99-ed4d4ff61301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use our function to replace values in the Top Ten column using apply()\n",
    "air2 = air.with_column('OZONE_PPM', air.apply(replace_true_nan, 'OZONE_PPM'))\n",
    "air2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dd8c7-e232-4aa1-a999-330822192a93",
   "metadata": {},
   "source": [
    "### ... or you can use Pandas\n",
    "What I just demonstrated is how to deal with nan's within the world of Data 8's data tables. Outside this class, Pandas dateframes are the weapon of choice for pythonistas working with tabular data. Pandas had many built in methods for dealing with missing data, and you'll need to learn pandas as you continue your python journey.\n",
    "\n",
    "Let's repeat the same operation of replacing nan's in the OZONE_PPM column using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc71f0a-1cee-4f97-99d3-463498173f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the data table to a pandas dataframe\n",
    "df = air.to_df()\n",
    "\n",
    "# Replace the nans in a column\n",
    "df['OZONE_PPM'] = df['OZONE_PPM'].replace(np.nan, 0)\n",
    "\n",
    "# Convert the pandas dataframe back into a data table\n",
    "air3 = Table().from_df(df)\n",
    "air3.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1206862-985a-4587-8a33-c5a75dec32fe",
   "metadata": {},
   "source": [
    "Pandas had many other methods for dealing with nans, including dropping those row, filling with a value, and intepolating between neighboring value. You can read all about it [here](https://pandas.pydata.org/docs/user_guide/missing_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4521bf9-8e1f-4df6-a9bb-850f325a9033",
   "metadata": {},
   "source": [
    "## Data Parsing \n",
    "\n",
    "Let's take a quick look at another one of the suggested data sets or the Group Project: Near Earth Objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd0ae8-c7ea-4f05-8f91-a5b6f806afbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = '../Group-project/data/cneos_closeapproach_data.csv'\n",
    "neo = Table.read_table(url)\n",
    "neo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83c4ad-eb42-4199-9297-be9b65d7e419",
   "metadata": {},
   "source": [
    "This is a really cool data set! Asteroids that may or may not be on a collision path with Earth. What's not to love? Well, the way the data are formatted, for one. Suppose we wanted to make a histogram of asteroid diameters. Look what we have to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e8e1d-49e7-4514-97c7-3f6858f0a402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neo.column('Diameter')[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956d4fe-78ac-458b-b989-d61d12509953",
   "metadata": {},
   "source": [
    "UGH!  Sometimes the diameter is given in meters. Sometimes in kilometers. For some a range is given. For other, it is a value with a +/-. \n",
    "\n",
    "**What do we do with this?**\n",
    "\n",
    "We need to make a plan, and document it as we go. Here it what I choose to do:\n",
    "\n",
    "1. If a range is given, find the average.\n",
    "2. Drop any +/-.\n",
    "3. Convert the value from a string to an number.\n",
    "4. Convert all diameters to meters.\n",
    "\n",
    "Rather than just give you the final function, I will walk you through the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf156ab-7bed-46f8-8898-3e220f0eed14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create test cases\n",
    "test1 = '250 m -  570 m'\n",
    "test2 = '0.459±0.004 km'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2c515-1f49-49fe-8580-d74be18e4bf5",
   "metadata": {},
   "source": [
    "**For test 1:**\n",
    "\n",
    "Notice that the first element in the string is the lower bound on the diameter and the second to last element is the upper bound. We can split the string (which returns a list of the values split on the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38371b7a-36bb-45eb-b908-883562451843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        print(x[0], x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e88f7-7cfa-4bed-8d6a-17f8bf66f2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_diameter(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bacb9-7774-4662-a13a-554d08158e1c",
   "metadata": {},
   "source": [
    "That is a good start. Now make the function return the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce21b1-9bcc-44a9-aa6c-705f40e3fc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        return np.mean([float(x[0]), float(x[-2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6c8bc-e93b-47fb-be7c-854da7864793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_diameter(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54267d2b-5912-4e5c-b3b9-db49386fd530",
   "metadata": {},
   "source": [
    "Looks good. Now let's tackle the second case. Instead of splitting on spaces, we will split on the '±', keeping the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f30f7f-1f74-4816-8171-c259f3820e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        return np.mean([float(x[0]), float(x[-2])])\n",
    "    elif '±' in x:\n",
    "        x = x.split('±')\n",
    "        print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e51ee4-c11e-4f23-b0ff-3d6360034da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_diameter(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17d080-c709-4289-94c9-b4e3a40464d9",
   "metadata": {},
   "source": [
    "Great! But we need to convert this to a number and from kilometers to meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4b405-a0bc-49f0-9ff4-42e1a4f06f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        return np.mean([float(x[0]), float(x[-2])])\n",
    "    elif '±' in x:\n",
    "        x = x.split('±')[0]\n",
    "        return 1000 * float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504e870-6fb4-42a5-8679-ca54808e0d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_diameter(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af714be-5590-4133-aaba-9ea56d81bf50",
   "metadata": {},
   "source": [
    "Bingo! But what if there is number somewhere in the diameter column that does not fit either of our two type cases? Better check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c54c1-ff2c-4863-8078-4c60d746a5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        return np.mean([float(x[0]), float(x[-2])])\n",
    "    elif '±' in x:\n",
    "        x = x.split('±')[0]\n",
    "        return 1000 * float(x)\n",
    "    else:\n",
    "        print(\"This value is unexpected:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02c8a6-2bb9-4b4d-9425-ea949b0b363a",
   "metadata": {},
   "source": [
    "Fingers crossed, we will apply this function to the entire column in the data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28810161-61ec-4603-a954-31865c85dbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neo2 = neo.with_column('Diameter', neo.apply(convert_diameter, 'Diameter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57f1f0-9fbb-4717-aaf6-d87468a8947c",
   "metadata": {},
   "source": [
    "*DARN!!* It turn out there are two more test cases needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be45930-ff32-4aec-a9dd-31a45ae700dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create test cases\n",
    "test1 = '250 m -  570 m'\n",
    "test2 = '0.459±0.004 km'\n",
    "test3 = '1.4 km'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebff98-5758-4e49-a092-275960db3223",
   "metadata": {},
   "source": [
    "For test case three, we are looking for strings that contain 'km', but not '±'. Since we already check for '±', we just need to add a check for 'km' after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe211c-d52e-44e0-834b-6c96a46ea268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_diameter(x):\n",
    "    if '-' in x:\n",
    "        x = x.split()\n",
    "        return np.mean([float(x[0]), float(x[-2])])\n",
    "    elif '±' in x:\n",
    "        x = x.split('±')[0]\n",
    "        return 1000 * float(x)\n",
    "    elif 'km' in x:\n",
    "        x = x.split()[0]\n",
    "        return 1000 * float(x)\n",
    "    else:\n",
    "        print(\"This value is unexpected:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e364b36-c00f-426b-8117-524cf35bccea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_diameter(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b4343-34c8-4511-8c94-08f4b3a9796b",
   "metadata": {},
   "source": [
    "Finally, we have to decide what to do about nans. These are the asteroids for which the diameter is unknown. If we change them to some default number, they could affect the distribution, so we should filter them out with the where() method  before with apply our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147a913-0a1a-40c0-b059-ff227c3ae542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diameter = neo.select('Diameter').where('Diameter', are.not_equal_to('nan'))\n",
    "diameter.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49d0b3-09a6-44dd-937f-4faa99ee2cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diameter_no_nan = Table().with_column('Diameter', diameter.apply(convert_diameter, 'Diameter'))\n",
    "diameter_no_nan.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6e01e-bb54-4292-bc22-f0c40cf249f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diameter_no_nan.hist('Diameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed90a7-7083-40d6-a160-53c4a7d8dbe0",
   "metadata": {},
   "source": [
    "Well, it worked, but what a boring histogram!  There must be a few large asteroids and many, many, small ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab4d33-104b-41a2-b58e-dcebabdc867f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(diameter_no_nan.column('Diameter'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1fd91-7c23-4366-9b0c-0b3064bd1a56",
   "metadata": {},
   "source": [
    "Let's limit our histogram to asteoroids under 1000 meters in diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75beb86-9ed6-4cc3-af63-16be96929cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diameter_no_nan.where('Diameter', are.below(1000)).hist('Diameter', bins=20)\n",
    "plt.title(\"Near-Earth Objects Diameters less than 1000 m\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade04ea1-8d70-4fd7-be20-de8138bffe18",
   "metadata": {},
   "source": [
    "# Concluding Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e41487-f6d0-46f4-ab11-b0250c72876f",
   "metadata": {},
   "source": [
    "Well, we did it, but it was a lot of work. \n",
    "\n",
    "Here is a very telling quote [ref](https://www.appier.com/en/blog/means-data-scientist-today):\n",
    "\n",
    ">What Makes for a Good Data Scientist\n",
    "\n",
    ">Of course, every job has some less lovable bits and the burden of the data scientist is data cleaning! In most cases, the data we gather is ‘dirty’, with errors and discrepancies in it. For example, data showing that sales of a product have dropped dramatically may simply mean that malfunctioning machines have failed to capture the data accurately.\n",
    "\n",
    ">Most data scientists will agree that data cleaning is the most boring part of this job. Our inside joke is that data science is 80 percent cleaning of data and 20 percent complaining about it!\n",
    "\n",
    ">But jokes aside, data cleaning is painstaking but important work. If not done right, it can have a huge impact on the accuracy and reliability of insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
