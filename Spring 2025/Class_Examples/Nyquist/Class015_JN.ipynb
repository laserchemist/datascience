{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "Elements of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypothesis Testing Learning Goals\n",
    "Develop and test an hypothesis\n",
    "- Hypothesis\n",
    "    - testable hypothesis\n",
    "    - statistic\n",
    "- Simulation: Sample the distribution\n",
    "    - Repeat and collect outcomes\n",
    "    - Iteration: \n",
    "        `for i in np.arange(samples)`\n",
    "- Examine resulting distribution of outcomes\n",
    "    - Probability distribution\n",
    "    - Uncertainty\n",
    "- p-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Fix for datascience plots\n",
    "import collections as collections\n",
    "import collections.abc as abc\n",
    "collections.Iterable = abc.Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A digression -- python formatting\n",
    "\n",
    "You know Python has a few formatting rules. Indentation is critical for defining structure in loops, functions, and conditional statements, for example. Beyond that, you can pretty much do as you like. The following formatting conventions, however, will make your code more readable.\n",
    "\n",
    "Black is a Python tool for checking formatting. You can actually install and run it to check your code, or you can simply paste some code you have written into the [Black Playground](https://ryanking13.github.io/black-playground-pyodide/) to see the suggested format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First Example: Paste into the playground. Note: the code will run as written\n",
    "\n",
    "a=2\n",
    "b=3\n",
    "c=a+b\n",
    "print( c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the foratted code below:\n",
    "# First Example: Paste into the playground. Note: the code will run as written\n",
    "\n",
    "\n",
    "a = 2\n",
    "b = 3\n",
    "c = a + b\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second example: Again, the code as written will run without error. But long lines are hard to read.\n",
    "# Create a list\n",
    "CST_departments = ['Earth & Environmental Science','Biology','Chemistry','Physics','Computer & Information Sciences','Mathematics']\n",
    "\n",
    "# Now loop over each element and print it.\n",
    "for dept in CST_departments:\n",
    "    print(dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the foratted code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formatting complex statements\n",
    "from datascience import *\n",
    "data = 'http://www2.census.gov/programs-surveys/popest/datasets/2010-2020/national/asrh/nc-est2020-agesex-res.csv'\n",
    "full_census_table = Table.read_table(data)\n",
    "partial_census_table = full_census_table.select('SEX', 'AGE', 'POPESTIMATE2010', 'POPESTIMATE2020')\n",
    "partial_census_table = partial_census_table.relabeled('SEX', 'GENDER').relabeled('POPESTIMATE2010', '2010').relabeled('POPESTIMATE2020', '2020')\n",
    "partial_census_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the foratted code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black makes some opinionated choices. You do not have to follow all of its formatting suggestions, but you should pick a consistant way to format your code and Black uses what many pythonistas consider to be best practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of digression..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datafile = \"/home/jovyan/datascience/Spring 2024/Mini Project I/Olympic_Data/winter_athletes.csv\"\n",
    "athletes = Table.read_table(datafile).sort(\"Year\",descending=True).where(\"Season\",\"Winter\")\n",
    "age_athletes = athletes.where(\"Age\",are.below(99)).where(\"Age\",are.above(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the top ten countries in number of Gold, silver, bronze medals, and total medals? You should have four sets of top ten countries for each of the scenarios. Generate the **five number summary** for each medal type for all countries.\n",
    "Hint: `.where(\"Medal\",are.not_equal_to(\"nan\"))` to get only medal winners. Consider how to create a column for the sum of the three medal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medals = athletes.where(\"Medal\", are.not_equal_to(\"nan\")).select(\"Team\", \"Medal\").pivot(\"Medal\", \"Team\")\n",
    "medals.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_medals = medals.column(\"Gold\") + medals.column(\"Silver\") + medals.column(\"Bronze\")\n",
    "medals = medals.with_column(\"Total Medals\", total_medals)\n",
    "medals.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top ten gold\n",
    "medals.sort(\"Gold\", descending=True).select(\"Team\", \"Gold\").take(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which sports (top 5) awarded the most medals in Lake Placid, New York (1980,\n",
    "https://www.lakeplacid.com/do/activities/olympic-sites )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sports that awarded the most medals in 1980\n",
    "medals_sport = athletes.where(\"Medal\", are.not_equal_to(\"nan\"))\n",
    "medals_sport.where(\"Year\", 1980).group(\"Sport\").sort(\"count\", descending=True).take(np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Plot the yearly trend in number of sports. Think of a strategy to code this. What is the trend? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "athletes.group([\"Year\", \"Event\"]).group(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "athletes.group([\"Year\", \"Event\"]).group(\"Year\").relabel(\"count\", \"Number of Events\").plot(\"Year\", \"Number of Events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Plot an overlay of gold, silver, and bronze medals as a function of year on the same plot excluding hockey. What is the trend? Are the medals awarded at a similar rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medals_per_year = athletes.where(\"Event\", are.not_containing(\"Hockey\")).pivot(\"Medal\", \"Year\").drop(\"nan\")\n",
    "medals_per_year.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medals_per_year.drop(\"Total Medals\").plot(\"Year\")\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(\"Medals per Year\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 06 TIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modifier = 11\n",
    "num_observations = 7\n",
    "\n",
    "def simulate_observations(modifier, num_observations):\n",
    "    \"\"\"Produces an array of 7 simulated modified die rolls\"\"\"\n",
    "    ...\n",
    "\n",
    "observations = ...\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How to make an empty array and append values\n",
    "test = make_array()\n",
    "np.append(test, 5)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Groundhogs\n",
    "![](https://i.natgeofe.com/n/fb6f0b10-50e0-4857-9246-012bbef02614/groundhog.jpg?w=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Hog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groundhogdata = Table.read_table('../../Lab05/GroundHogData/summarizedGroundhogData_20210326.csv')\n",
    "groundhogdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yes_late = groundhogdata.where('shadowPres', 'yes').where('earlyOrLate', 'late')\n",
    "no_early = groundhogdata.where('shadowPres', 'no').where('earlyOrLate', 'early')\n",
    "\n",
    "correct_tbl = yes_late.append(no_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_correct = correct_tbl.num_rows / groundhogdata.num_rows * 100\n",
    "print(f\"The groundhogs were correct {num_correct:0.1f} percent of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is 51.1% is correct \"significantly\" better than random guessing?\n",
    "\n",
    "To answer this question we need to simulate guessing randomly 520 times (the size of our data set) and see what fractionof the time we do this much better than 50-50 by guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shadow_options = make_array('yes', 'no')\n",
    "spring_options = make_array('late', 'early')\n",
    "num_observations = groundhogdata.num_rows\n",
    "num_simulations = 1500\n",
    "num_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulate by guessing -- this is a single trial.\n",
    "\n",
    "right = 0 \n",
    "wrong = 0\n",
    "\n",
    "for obs in range(num_observations):\n",
    "    shadow = np.random.choice(shadow_options)\n",
    "    spring = np.random.choice(spring_options)\n",
    "    \n",
    "    if shadow == 'yes' and spring == 'late':\n",
    "        right += 1\n",
    "    elif shadow == 'no' and spring == 'early':\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "simulated_num_correct = right / num_simulations\n",
    "simulated_num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function so we can generate many trials.\n",
    "def sim_ground(repeats):\n",
    "    correct_obs = []\n",
    "    for i in np.arange(repeats):\n",
    "        right = 0 \n",
    "        wrong = 0\n",
    "        for obs in range(num_observations):\n",
    "            shadow = np.random.choice(shadow_options)\n",
    "            spring = np.random.choice(spring_options)\n",
    "            if shadow == 'yes' and spring == 'late':\n",
    "                right += 1\n",
    "            elif shadow == 'no' and spring == 'early':\n",
    "                right += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        simulated_num_correct = right / num_observations\n",
    "        correct_obs.append(simulated_num_correct)\n",
    "    return correct_obs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of 1500 trials\n",
    "plt.hist(sim_ground(num_observations),bins=np.arange(0.4,0.6,.01),color = \"skyblue\", ec=\"red\")\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hogsimdata = Table().with_columns(\"Correct\",sim_ground(num_simulations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The red dot shows the groundhog prediction accuracy\n",
    "hogsimdata.hist(0,bins=np.arange(0.4,0.6,.01))\n",
    "plt.scatter(num_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What is the probabilty of doing better than the groundhogs with random guessing?\n",
    "np.count_nonzero(hogsimdata.column('Correct') >= num_correct/100) / num_simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essex Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogdata.where('hogID',\"EE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tbl.where('hogID',\"EE\").sort('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = correct_tbl.where('hogID',\"EE\").num_rows / groundhogdata.where('hogID',\"EE\").num_rows * 100\n",
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hogsimdata.hist(0,bins=np.arange(0.4,0.6,.01))\n",
    "plt.scatter(num_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(hogsimdata.column('Correct') >= num_correct/100) / num_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_observations = 7\n",
    "hogsimdata = Table().with_columns(\"Correct\",sim_ground(num_simulations))\n",
    "hogsimdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hogsimdata.hist(0,bins=np.arange(0.1,0.9,.01))\n",
    "hogsimdata.hist(bins=15)\n",
    "plt.scatter(num_correct/100, 0, color='red', s=200);\n",
    "plt.title('Simulated Groundhog outcomes')\n",
    "plt.savefig('sim_ground_correct.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(hogsimdata.column('Correct') >= num_correct/100) / num_simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement in the paper\n",
    "This study was the result of a truly laboratory-driven effort that started over speculation on a Friday at the campus pub and has led to a cumulative effort of students in the Community Ecology and Energetics Laboratory at Lakehead University over several years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
