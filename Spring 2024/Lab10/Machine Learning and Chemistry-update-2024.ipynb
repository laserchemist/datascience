{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning and prediction\n",
    "Elements of Data Science   \n",
    "In this laboratory we will use training data to predict outcomes. We will first test these ideas using our Old Faithful data again. Next we will look at data on the iris flower to classify iris' based on sepal width and length. In our culminating activity we will predict molecular acidity using data computed by [Prof. Vince Voelz](http://www.voelzlab.org) in the Temple Chemistry department and a graduate student, Robert Raddi. See their paper: [Stacking Gaussian processes to improve pKa predictions in the SAMPL7 challenge](https://link.springer.com/epdf/10.1007/s10822-021-00411-8?sharing_token=yLV8dMXdxg40M_Ds_2Rhsfe4RwlQNchNByi7wbcMAY6fCl3bMLQiAhJzS2zZw-SwUkz490heLLZu1bPJ8T5LHXo1WvZkp0AJmWzXo71rszl8UaPxjqtqR-oARfxWGrTiCV0rNXy0C7IVzX6yoMYTPv2ZJfnQS-zF1pYvL8ESsUI%3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_name = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from training data\n",
    "A key concept in machine learning is using a subset of a dataset to train an algorithm to make estimates on a separate set of test data. The quality of the machine learning and algorithm can be assesed based on the accuracy of the predictions made on test data. Many times there are also parameters sometimes termed hyper-parameters which can be optimized through an iterative approach on test or validation data. In practice a dataset is randomly split into training and test sets using sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Nearest neighbor</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k nearest neighbor\n",
    "We will examine one machine learning algorithm in the laboratory, k nearest neighbor. Many of the concepts are applicable to the broad range of machine learning algorithms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gofer.ok import check\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "#from IPython.display import Image\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from jupyterquiz import display_quiz\n",
    "import json\n",
    "from IPython.core.display import HTML\n",
    "from ipywidgets import interact, interactive, fixed,IntSlider\n",
    "import ipywidgets as widgets\n",
    "import EDS\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor concept\n",
    "The training examines the characteristics of *k* nearest neighbors to the data point for which a prediction will be made. Nearness is measured using several different [metrics](https://www.nhm.uio.no/english/research/infrastructure/past/help/similarity.html) with Euclidean distance being a common one for numerical attributes.  \n",
    "Euclidean distance:   \n",
    "1-D $$ d(p,q) = \\sqrt{(p-q)^{2}} $$   \n",
    " 2-D $$ d(p,q) = \\sqrt{(p_1-q_1)^{2}+(p_2-q_2)^{2}} $$\n",
    " \n",
    " For multiple points (rows):\n",
    " 2-D $$ d(p,q) = \\sum{{\\sqrt{((p_1-q_1)^{2}+(p_2-q_2)^{2}}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example in 2-D Cartesian coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3, 8, 5, 6, 1, 9, 8])\n",
    "y = np.array([4, 5, 7, 4, 6, 9, 4])\n",
    "testx = np.array([4])\n",
    "testy = np.array([8])\n",
    "n = list(np.arange(1,8))\n",
    "color = \"red\"\n",
    "plt.scatter(x, y, c = color, s=30,label = 'training points')\n",
    "plt.scatter(testx, testy, c = 'blue', s=100, label = 'test point')\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (x[i]+.1, y[i]+.1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Euclidean distances\n",
    "$ d(x,y) = \\sqrt{(x_{test}-x_{train})^{2}+(y_{test}-y_{train})^{2}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt((testx - x)**2 + (testy - y)**2)  # Compute numpy array of distances from training point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"training point\\t distance\")\n",
    "for i, txt in enumerate(n):\n",
    "    print(f'{txt:d}  \\t\\t {distance[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort to see the nearest in order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training point\\t distance\")\n",
    "for i, dist in zip(np.argsort(distance)+1, np.sort(distance)) :\n",
    "    print(f'{i:d}   \\t\\t {dist:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training point 3 is the nearest neighbor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try different attribute values in the following 2D Euclidean distance example code below to get a feel for the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to compute an Euclidean distance between two 2-D points\n",
    "d_p_q = np.sqrt(sum((make_array(2,3)-make_array(4,3))**2))\n",
    "d_p_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A couple quick review questions about nearest neighbor below, select the best answer (multiple tries ok). Execute the below cell to reveal the self-check quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions=json.load(file)    \n",
    "display_quiz(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k nearest  neighbor regression\n",
    "We will use the k nearest neighbor algorithm to make predictions of wait time in minutes following an eruption duration of a given number of minutes (independent variable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"data/faithful.csv\")\n",
    "faithful.scatter(0, 1, fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows how to get values from a row in a Table as an array as is done in row_distance. Note in the faithful data case we will only consider the duration column in nearest neighbor computation but in examples below we will use a 2-D array of attributes with the iris data and a 10-D array in the chemistry and molecular acidity case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 1.** </font>\n",
    "Use the datascience .split(n) Table method to split the dataset into 80% training and 20% test. The argument for .split(n) method,n, needs to be an integer. [See datascience documentation](https://datascience.readthedocs.io/en/master/_autosummary/datascience.tables.Table.split.html#datascience.tables.Table.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf, testf = ...\n",
    "print(trainf.num_rows, 'training and', testf.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.** </font>\n",
    "Define a function which is the Euclidean distance between two values. Use the last two example code cells above as inspiration. This is where we will compute the distance between two *duration* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt1, pt2):\n",
    "    \"\"\"The distance between two points, represented as arrays.\"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest of the nearest neighbor algorithm\n",
    "Execute these cells to create the complete algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2)) # Need to convert rows into arrays\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, test, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, test, output).sort('Distance').take(np.arange(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 3.** </font>\n",
    "We will look at the Table containing the test data set and then we can take a specific row using `.take(5)` which would take the 6th row of the test data (zero referenced). This specific row will be used to test the prediction of a wait time given the duration specified in the test row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example below will create a test row without the `wait` data. The value of `wait` will be predicted by the nearest neighbor machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf.take(5).drop('wait').row(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a test row from the test data (testf), drop the prediction column and use the closest function to see the top 10 closest points to the target in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = testf...row(...)\n",
    "test_row   # This should display data contained in selected row in testf table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ... # Number of nearest neighbors\n",
    "closest(...,test_row,...,'wait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 4.** </font>\n",
    "Predict the value for this row using the defined predict_nn function below and compare to the value reported for wait in the test data. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(test):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    k = 5\n",
    "    return np.average(closest(trainf, test, k , 'wait').column('wait'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionf = ...  # This is the value predicted for wait using the average of the k nearest neighbors in the test set\n",
    "actual = ...\n",
    "print(predictionf,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 5. Predictions** </font>\n",
    "Now we will make predictions for the whole data set using the apply Table method. We will then look at the root mean squared error (RMSE) for the nearest neighbor fit and a scatter plot. Try adjusting the value of k in the predict_nn function to see it's effect on the quality of fit by rerunning these cells. Are the predicted points in a **perfect** straight line, why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf = testf.with_columns(\"predict\",testf.apply(predict_nn,\"duration\"))\n",
    "nn_test_predictions = testf.column(\"predict\")\n",
    "test_wait = testf.column(\"wait\")\n",
    "rmse_nn = np.mean((test_wait - nn_test_predictions) ** 2) ** 0.5\n",
    "\n",
    "print('Test set RMSE for nearest neighbor regression:', round(rmse_nn,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf.scatter(\"duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify iris flower data with machine learning\n",
    "Next we will take on the problem of classifying iris data into three categories, setosa, versicolor, and virginica. Here we will also learn the basics of the k nearest neighbor algorithm.\n",
    "\n",
    "The first data set we will look at consists of 50 samples from three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured including the length and the width of the sepals and petals, in centimeters for each observation.\n",
    "<br><center><img src='iris.png' width=150 height=150><br>Iris stainglass, J.R. Smith</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "# Load iris data\n",
    "iris = datasets.load_iris()\n",
    "# We only take the first two features. \n",
    "iris_table = Table().with_columns(\"Name\",iris.target,iris.feature_names[0],iris.data[:,0],iris.feature_names[1],iris.data[:,1])\n",
    "iris_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 6.** </font>\n",
    "Train and test split the iris_table @ 80% as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i, test_i = ...\n",
    "print(train_i.num_rows, 'training and', test_i.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 7.** </font>\n",
    "With classification we need to use training data to decide how to classify data given a set of attributes, sepal length and sepal width in this case. Create a function which returns the majority classification among three possibilities in \"Name\" coded as 0, 1, 2 (setosa, versicolor, and virginica respectively). The `and` below combines two conditionals. For example,  (twos > ones) and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(topkclasses):\n",
    "    virginica = topkclasses.where('Name', are.equal_to(2)).num_rows\n",
    "    versicolor = ...\n",
    "    setosa = ...\n",
    "    # Now test to see what the majority name for each k class\n",
    "    if ... and ...:\n",
    "        return 2\n",
    "    elif ... and ...:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(training, new_point, k):\n",
    "    closestk = closest(training, new_point, k,\"Name\")\n",
    "    topkclasses = closestk.select('Name')\n",
    "    return majority(topkclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row_num = ...\n",
    "k = ...\n",
    "print(\"Prediction: \",classify(train_i,test_i.drop(...).row(test_row_num),k),\" Actual: \",test_i.select(\"Name\").row(test_row_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test_attributes, k):\n",
    "    pred = []\n",
    "    for i in np.arange(test_attributes.num_rows):\n",
    "        pred.append(classify(train,test_attributes.row(i),k))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 8.** </font>\n",
    "Make a new table called prediction which includes original columns of test Table but also includes a \"predict\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ...\n",
    "prediction = test_i.with_columns(\"predict\",...)\n",
    "prediction.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision outcomes for test set\n",
    "#### <font color=blue> **Question 9.** </font>\n",
    "Use above prediction Table to make a scatter plot of the color coded predictions based on the tweo attributes(use group=\"predict\" in scatter plot after specifying x and y axis based on attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.drop(\"Name\").scatter(...,...,group='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy plot showing color coded decision boundaries\n",
    "We can make a more informative plot by predicting on a grid of attribute values as shown below. Seaborn is an add-on to the Matplotlib plotting we have been using which provides more control of plotting. Execute (this may take a minute+) and study the below input and resulting output for your information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colors(iris, y, cmap):\n",
    "    colors = []\n",
    "    cdict = {'setosa':0, 'virginica':2, 'versicolor':1}\n",
    "    for x in iris.target_names[y]:\n",
    "        colors.append(cmap[cdict[x]])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = 0.1  # step size in the mesh\n",
    "k = 10\n",
    "x_min, x_max = iris.data[:, 0].min() - 1, iris.data[:, 0].max() + 1\n",
    "y_min, y_max = iris.data[:, 1].min() - 1, iris.data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "## Create a grid of predictions in a Table\n",
    "attribute_grid = Table().with_columns(\n",
    "    iris.feature_names[0],\n",
    "    np.c_[xx.ravel(), yy.ravel()][:, 0],\n",
    "    iris.feature_names[1],\n",
    "    np.c_[xx.ravel(), yy.ravel()][:, 1],\n",
    ")\n",
    "\n",
    "Z = np.array(predict(train_i, attribute_grid, k))\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap([\"orange\", \"cyan\", \"cornflowerblue\"])\n",
    "cmap_bold = [\"darkorange\", \"c\", \"darkblue\"]\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=.3)\n",
    "\n",
    "# Plot the test points but convert to numpy arrays\n",
    "predictions = prediction.column(\"predict\")\n",
    "attribute1 = prediction.column(1)\n",
    "attribute2 = prediction.column(2)\n",
    "plt.scatter(\n",
    "    x=attribute1,\n",
    "    y=attribute2,\n",
    "    c=make_colors(iris, predictions, cmap_bold),\n",
    "    alpha=.7,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i')\" % (k))\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 10.** </font>\n",
    "Comment on the quality of the predictions by <font color='blue'>\n",
    "1. <font color='green'>Your nearest neighjbor algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Answers here </font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecules and predicting acidity measured by pKa\n",
    "Within the Jupyter notebook we can also analyze molecules and their molecular data using the library  RDKit. RDKit adds the ability to visualize 2D and 3D molecular structures. We can apply many of the data science tools we have learned to molecular data as well. <br>First we will briefly look at acid-base chemistry and how acidity is defined. pH is a measure of the acidity of a water-based (aqueous) solution. A pH of 1 is acidic, a pH of 7 is neutral and a pH of 14 is basic.  Next we will use some computed atributes of a large set of molecules to train a k nearest neighbor model to predict acidity. We will use a range of attributes including the partial charges on atoms adjacent to the acidic proton, molecular weight, solvent accessible surface area (SASA), carbon-oxygen bond order, and some thermochemistry measures all of which may help predict acidity with a lower pKa indicating a stronger (weak) acid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acid-base and pKa background\n",
    "A very brief background on acid - base equilibria demonstrated for glycine. See [OpenStax Chemistry](https://openstax.org/books/chemistry-2e/pages/14-introduction) for details based on interest.\n",
    "<br><center><img src='acid_base_pKa.png' width=900></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDKit\n",
    "[RDKit](https://www.rdkit.org/docs/Cookbook.html) is a specialized library to handle the complexities of molecules within Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying defaults\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "# Options\n",
    "DrawingOptions.bondLineWidth=1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='magenta'> Load detailed molecular data for 600 molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = Table().read_table('pKa_med.csv')\n",
    "molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 11.** </font>Select an amino acid \n",
    " Use the Table above to view data for an amino acid of your selection from the 21 amino acids which are building blocks of proteins. Note: not all amino acids are in the data set, try another if missing. See [web page](https://i.pinimg.com/originals/a2/fd/dd/a2fddd4ad8b9067bfeb0d6f51cf28e71.jpg) for possible choices. Hint: use are.containing within the .where() Table method. For example below we can find compounds which contain a methyl group (CH$_3$). We get 55 rows (records)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methyl = molecules.where(\"Name\",are.containing(\"methyl\"))\n",
    "methyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino = molecules.where(\"Name\",are.containing(\"...\"))\n",
    "amino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q11.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display molecular structure\n",
    "[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) is a shorthand language to describe molecular structure. Execute each structure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"[NH2+]CC(O)=O\") # Glycine an amino acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "EDS.smiles3D(\"[NH2+]CC(O)=O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"[H]-O-[H]\") #Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"[CH3]\") #Methyl radical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"C-C-O\") #Ethanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDS.smiles3D(\"C-C-O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pKa data examination\n",
    "Now we will look at a data set derived from the above data but with computed molecular attributes for our machine learning. This data set is computed and described by  [Prof. Vince Voelz](http://www.voelzlab.org) in the Temple Chemistry department and a graduate student, Robert Raddi. See their paper: [Stacking Gaussian processes to improve pKa predictions in the SAMPL7 challenge](https://link.springer.com/epdf/10.1007/s10822-021-00411-8?sharing_token=yLV8dMXdxg40M_Ds_2Rhsfe4RwlQNchNByi7wbcMAY6fCl3bMLQiAhJzS2zZw-SwUkz490heLLZu1bPJ8T5LHXo1WvZkp0AJmWzXo71rszl8UaPxjqtqR-oARfxWGrTiCV0rNXy0C7IVzX6yoMYTPv2ZJfnQS-zF1pYvL8ESsUI%3D)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load molecular data set with additional descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = Table().read_table('pKa_small.csv')\n",
    "molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of pKa, molecular weight (g/mol), and ∆H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules.hist('pKa',bins=25, edgecolor=\"black\", linewidth=1.2)\n",
    "molecules.hist('Weight',bins=25, edgecolor=\"black\", linewidth=1.2)\n",
    "molecules.hist('∆H',bins=25, edgecolor=\"black\", linewidth=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>Sample molecules in our data set</font>\n",
    "Take them for a spin by clicking and dragging on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rowid in np.random.choice(np.arange(molecules.num_rows),4):\n",
    "    print(molecules['Name'][rowid],' pKa: ',molecules['pKa'][rowid], ' Molecular Weight (g/mol): ',molecules['Weight'][rowid])\n",
    "    EDS.smiles3D(molecules['smiles'][rowid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>Pharmaceuticals in our data set</font>\n",
    "Below is a sampling of the many pharmaceuticals in our data set with 2D views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celecoxib = Chem.MolFromSmiles(molecules.where('Name','celecoxib')['smiles'][0])\n",
    "celecoxib.SetProp('Name',molecules.where('Name','celecoxib')['Name'][0]+' (NSAID) pKa: '+str(molecules.where('Name','celecoxib')['pKa'][0]))\n",
    "sertraline = Chem.MolFromSmiles(molecules.where('Name','Sertraline')['smiles'][0])\n",
    "sertraline.SetProp('Name',molecules.where('Name','Sertraline')['Name'][0]+' (anti-depressant, SSRI) pKa: '+str(molecules.where('Name','Sertraline')['pKa'][0]))\n",
    "losartin = Chem.MolFromSmiles(molecules.where('Name','Losartan')['smiles'][0])\n",
    "losartin.SetProp('Name',molecules.where('Name','Losartan')['Name'][0]+' (hypertension,  angiotensin II receptor blocker) pKa: '+str(molecules.where('Name','Losartan')['pKa'][0]))\n",
    "'Losartan'\n",
    "Draw.MolsToGridImage(\n",
    "    [celecoxib, sertraline, losartin],\n",
    "    legends=[celecoxib.GetProp(\"Name\"),sertraline.GetProp(\"Name\"), losartin.GetProp(\"Name\")],\n",
    "    molsPerRow=3,\n",
    "    subImgSize=(400, 250),\n",
    "    useSVG=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can look at the structures and data on several derivatives of acetic acid by executing the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display molecular structure from dataset\n",
    "[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) is a shorthand language to describe molecular structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example from smiles string from molecules Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(molecules['Name'][22],'smiles string: ', molecules['smiles'][22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own... 2D and 3D structures using `Chem.MolFromSmiles()` and `EDS.smiles3D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected amino acid 2D molecular structure\n",
    "Try it out for fun! Use the same above syntax and the SMILES string from your above Table to display a 2D amino acid structure from your selection. Even if there is no rdkit, try your hand at the SMILES molecular description. The 21 basic amino acid protein building blocks are given in a [helpful table](https://www.aatbio.com/data-sets/amino-acid-reference-chart-table) along with their smiles string to use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"My chosen amino acid is:\",...)\n",
    "smile_struct = '...'\n",
    "\n",
    "Chem.MolFromSmiles(smile_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDS.smiles3D(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nearest Neighbor\n",
    "For machine learning we will use the 5 features available in the molecules Table after dropping the smiles molecular structures string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection of attributes/features for training and prediction\n",
    "We need to select the features that we will use in the training. These will include the molecular weight (g/mol), Change in Enthalpy (kJ/mol) (prot-deprot), ∆G_solv (kJ/mol) (prot-deprot), the bond order to the atom for which the acidic proton is bound, and the solvent accessible surface area (SASA). We also keep the labels and smiles string as well as the pKa we will train on. In a second round we will add features corresponding to partial charges on nearby atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at caprilic acid which is a fatty acid found in palm oil and coconut oil to understand the various features we are using in our machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules.where('Name','Caprylic acid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules.where('Name','Caprylic acid')['smiles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(molecules.where('Name','Caprylic acid')['smiles'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize, train, test split\n",
    "#### <font color=blue> **Question 12.** </font>\n",
    "First we need to convert all numerical values to standard units. This is because different features have differing magnitudes leading to deviations in computed Euclidean distances. You will split the molecular Table into train and test data using 80% for training and remembering that the split must be an integer using int() function. Again we will select certain rowsas attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules.labels[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pKa_s = molecules.select('Name','pKa','smiles')\n",
    "for label in molecules.labels[2:-1]:\n",
    "    print('Standardizing: ',label)\n",
    "    pKa_s = pKa_s.with_columns(label,standard_units(molecules[label]))\n",
    "pKa_s   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time to split the data, your turn... rember to use the standardized data in `pKa_s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = pKa_s.split(...)\n",
    "print(train.num_rows, 'training and', test.num_rows, 'test instances.')\n",
    "\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q12.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our k nearest neighbors code\n",
    "\n",
    "Remember our the k nearest neighbor code from above which wewill again use here.\n",
    "<code>\n",
    "    def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2))\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, example, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, example, output).sort('Distance').take(np.arange(k))\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test algorithm\n",
    "Execute these cells to define the predict_nn function for pKa, pick a  row, predict and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(test):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    k = 10\n",
    "    return np.average(closest(train.drop('Name','smiles'), test, k, 'pKa').column('pKa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine 1 row in test set to try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop().take(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at closest in training set to test row, need to drop pKa and smiles string from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.take(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Target pKa: ',test.take(90)['pKa'][0])\n",
    "k = 25\n",
    "closest(train.drop('Name','smiles'), test.drop('Name','smiles','pKa').row(90), k, 'pKa').select('pKa','Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pKa_pre = closest(train.drop('Name','smiles'), test.drop('Name','smiles','pKa').row(90), k, 'pKa')['pKa'].mean()\n",
    "print(f'Prediction: {pKa_pre:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we use test data in both cases we get exact match (Distance = 0) and no training, not machine learning but matching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest(test.drop('Name','smiles'), test.drop('Name','smiles','pKa').row(100), k, 'pKa').select('pKa','Distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of experimental acidity to be predicted\n",
    "#### *Question*  \n",
    "Make two histograms of acidity measured by pKa in the training data and test data. Compare the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 13.** </font>Prediction time\n",
    "Now predict the pKa of the 10th molecule in the test dataset using predict. We need to drop the experimental pKa, the smiles string, and the name to create a test_nn_row with the attributes for the k nearest neighbor. Discuss the quality of the fit and the name of the name of the molecule from column 1. Repeat for two more rows and discuss the prediction quality. Keep in mind that the prediction of pKa is a very challenging task for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nn_row = ....row(9)\n",
    "test_nn_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_nn(test_nn_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Experimental pKa:', test.column('pKa').item(9))\n",
    "print('Predicted pKa using nearest neighbors:', round(predict_nn(test_nn_row),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q13.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot knn prediction success\n",
    "Execute the next three cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(test, k=5):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    return np.mean(closest(train.drop('Name','smiles'), test, k, 'pKa').column('pKa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pKa = np.array([])\n",
    "predict_pKa = np.array([])\n",
    "for i in np.arange(test.num_rows):\n",
    "    exp_pKa = np.append(exp_pKa,test.column('pKa').item(i))\n",
    "    test_nn_row = test.drop('Name','pKa','smiles').row(i)\n",
    "    predict_pKa = np.append(predict_pKa,predict_knn(test_nn_row) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exp_pKa), len(predict_pKa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exp_pKa, predict_pKa)\n",
    "# calculate equation for regression line\n",
    "z = np.polyfit(exp_pKa, predict_pKa, 1)\n",
    "p = np.poly1d(z)\n",
    "# add trendline to plot\n",
    "plt.plot(\n",
    "    exp_pKa, p(exp_pKa), \"blue\", label=\"{}\".format(p)+' k:'+str(k)\n",
    ")  # Equation of line placed in legend from label\n",
    "plt.xlabel(\"Experimental pKa\")\n",
    "plt.ylabel(\"Predicted pKa\")\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions on our k nearest neighbor model\n",
    "#### <font color=blue> **Question 14.** </font>\n",
    "What is the interpretation of the slope and the intercept in the above plot? What would the slope and intercept be in the case of a perfect match between `Predicted pKa` and `Experimental pKa`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Your discussion </font>\n",
    "***   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the overall quality of our machine learning prediction based on the above plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Your discussion </font>\n",
    "***   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining dependence on k parameter.\n",
    "#### <font color=blue> **Question 15.** </font>\n",
    "Now we will iterate through different values of k to decide which is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try a few values for k to try to optimize the value of k which is known as a hyperparameter. We need a new version of `predict_nn` that also has an argument of k with a default value of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(test, k=5):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    return np.mean(closest(train.drop('Name','smiles'), test, k, 'pKa').column('pKa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of 4 to 7 values of k to test with the same plot as is in Question 13 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [...]:\n",
    "    exp_pKa = make_array()\n",
    "    predict_pKA = make_array()\n",
    "    for i in np.arange(test.num_rows):\n",
    "        exp_pKa = np.append(exp_pKa, test.column(\"pKa\").item(i))\n",
    "        example_nn_row = test.drop('Name','pKa','smiles').row(i)\n",
    "        predict_pKA = np.append(predict_pKA, predict_knn(example_nn_row, k))\n",
    "    plt.scatter(exp_pKa, predict_pKA)\n",
    "    z = np.polyfit(exp_pKa, predict_pKA, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(\n",
    "        exp_pKa, p(exp_pKa), \"blue\", label=\"{}\".format(p), color='teal',alpha=0.7)  # Equation of line placed in legend from label\n",
    "    plt.xlabel(\"Experimental pKa\")\n",
    "    plt.ylabel(\"Predicted pKa\")\n",
    "    plt.title(\"k = \" + str(k))\n",
    "    plt.legend(fontsize=\"small\")\n",
    "    plt.savefig('k-plots.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> *Question:* Which value of `k` makes the best estimation?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q14.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different knn weighting schemes\n",
    "All of the nearest n neighbors receive the same consideration in determining the prediction. It makes sense that points that are 'nearer' may be more important or weightier. Below are figures showing the unweighted approach we have been using, a weighting scheme based on inverse distance (1/distance), and an exponetial weighting scheme for 4-ethylphenol.<br>\n",
    "<img src='ethylphenol.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <center>**knn weighting plots**\n",
    "---\n",
    "<center>k = 5 with neighboring 5 molecular structures<br><img src='knn_equal_weighting_molecule.png'></center><br>\n",
    "\n",
    "---\n",
    "<center>k = 10<br>\n",
    "<img src='knn_inverse_weighting.png'><img src='knn_exponential_weighting.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Repeat the above replacing the `predict_knn` with the first weighting scheme which is 1/distance weighting in the `predict_knn_weighted` function and then the `predict_knn_weighted_exp` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn_weighted(example,k):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    dist_table = closest(train.drop('Name','smiles'), example, k, 'pKa')    \n",
    "    total_inverse = np.sum(1/dist_table['Distance'])\n",
    "    dist_table=dist_table.with_columns('knn_weighting',(1/dist_table['Distance'])*total_inverse)\n",
    "    sum_weight = np.sum(dist_table['knn_weighting'])\n",
    "    weighted_mean_pKa = np.sum(dist_table['pKa']*dist_table['knn_weighting']/sum_weight)\n",
    "    return weighted_mean_pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn_weighted_exp(example,k):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    dist_table = closest(train.drop('Name','smiles'), example, k, 'pKa')    \n",
    "    total_exp = np.sum(np.exp(-dist_table['Distance']))\n",
    "    dist_table=dist_table.with_columns('knn_weighting',(np.exp(-dist_table['Distance']))*total_exp)\n",
    "    sum_weight = np.sum(dist_table['knn_weighting'])\n",
    "    weighted_mean_pKa = np.sum(dist_table['pKa']*dist_table['knn_weighting']/sum_weight)\n",
    "    return weighted_mean_pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [...]:\n",
    "    exp_pKa = make_array()\n",
    "    predict_pKA = make_array()\n",
    "    for i in np.arange(test.num_rows):\n",
    "        exp_pKa = np.append(exp_pKa, test.column(\"pKa\").item(i))\n",
    "        example_nn_row = test.drop('Name','pKa','smiles').row(i)\n",
    "        predict_pKA = np.append(predict_pKA, ...(example_nn_row, k))  # PLACE TO PUT NEW FUNCTION\n",
    "    plt.scatter(exp_pKa, predict_pKA)\n",
    "    z = np.polyfit(exp_pKa, predict_pKA, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(\n",
    "        exp_pKa, p(exp_pKa), \"blue\", label=\"{}\".format(p), color='teal',alpha=0.7)  # Equation of line placed in legend from label\n",
    "    plt.xlabel(\"Experimental pKa\")\n",
    "    plt.ylabel(\"Predicted pKa\")\n",
    "    plt.title(\"k = \" + str(k))\n",
    "    plt.legend(fontsize=\"small\")\n",
    "    plt.savefig('k-plots.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font blue>Which weighting scheme works best?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <font color=blue> **Question 16.** </font>\n",
    "At the end of each lab, please include a reflection. \n",
    "* How did this lab go? \n",
    "* Can you think of other applications of k-means clustering?\n",
    "* Were there questions you found especially challenging you would like your instructor to review in class? \n",
    "* How long did the lab take you to complete?\n",
    "\n",
    "Share your feedback so we can continue to improve this class!\n",
    "\n",
    "**Insert a markdown cell below this one and write your reflection on this lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Draw a 3D structure of your favorite molecule encountered in this lab using a smiles string and the `EDS.smiles3D()` function. Why is it your favorite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDS.smiles3D(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All finished...\n",
    "Run checks and submit .html and .ipynb files after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "checks = [1,2,3,4,6,7,8,11,12,13,14,15]\n",
    "total = len(checks)\n",
    "for x in checks:\n",
    "    print('Testing question {}: '.format(str(x)))\n",
    "    g = check('tests/q{}.py'.format(str(x)))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))\n",
    "print(\"Nice work \",Your_name, user)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### <font color='brown'>REFERENCE: k nearest neghbors toolkit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf, testf = table.split(int(0.80*table.num_rows))\n",
    "print(trainf.num_rows, 'training and', testf.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt1, pt2):\n",
    "    \"\"\"The distance between two points, represented as arrays.\"\"\"\n",
    "    return np.sqrt(sum((pt1 - pt2) ** 2))\n",
    "def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2)) # Need to convert rows into arrays\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, test, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, test, output).sort('Distance').take(np.arange(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(topkclasses):\n",
    "    two = topkclasses.where('Name', are.equal_to(2)).num_rows\n",
    "    one = topkclasses.where('Name', are.equal_to(1)).num_rows\n",
    "    zero = topkclasses.where('Name', are.equal_to(0)).num_rows\n",
    "    if (two> one) and (two > zero):\n",
    "        return 2\n",
    "    elif one>zero:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def classify(training, new_point, k):\n",
    "    closestk = closest(training, new_point, k,\"Name\")\n",
    "    topkclasses = closestk.select('Name')\n",
    "    return majority(topkclasses)\n",
    "def predict(train, test_attributes, k):\n",
    "    pred = []\n",
    "    for i in np.arange(test_attributes.num_rows):\n",
    "        pred.append(classify(train,test_attributes.row(i),k))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Units for features/attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)  \n",
    "pKa_s = molecules.select('Name','pKa','smiles')\n",
    "for label in molecules.labels[2:-1]:\n",
    "    print('Standardizing: ',label)\n",
    "    pKa_s = pKa_s.with_columns(label,standard_units(molecules[label]))\n",
    "pKa_s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(test, k=5):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    return np.mean(closest(train.drop('Name','smiles'), test, k, 'pKa').column('pKa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate weighting of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn_weighted(example,k):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    dist_table = closest(train.drop(0), example, k, 'pKa')    \n",
    "    total_inverse = np.sum(1/dist_table['Distance'])\n",
    "    dist_table=dist_table.with_columns('knn_weighting',(1/dist_table['Distance'])*total_inverse)\n",
    "    sum_weight = np.sum(dist_table['knn_weighting'])\n",
    "    weighted_mean_pKa = np.sum(dist_table['pKa']*dist_table['knn_weighting']/sum_weight)\n",
    "    return weighted_mean_pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn_weighted_exp(example,k):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    dist_table = closest(train.drop(0), example, k, 'pKa')    \n",
    "    total_exp = np.sum(np.exp(-dist_table['Distance']))\n",
    "    dist_table=dist_table.with_columns('knn_weighting',(np.exp(-dist_table['Distance']))*total_exp)\n",
    "    sum_weight = np.sum(dist_table['knn_weighting'])\n",
    "    weighted_mean_pKa = np.sum(dist_table['pKa']*dist_table['knn_weighting']/sum_weight)\n",
    "    return weighted_mean_pKa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
