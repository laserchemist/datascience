{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Sampling and Simulation\n",
    "*Elements of Data Science* <br>\n",
    "Welcome to Module 2 and lab 6! This week, we will go over conditionals and iteration, and introduce the concept of randomness. All of this material is covered in [Chapter 9](https://inferentialthinking.com/chapters/09/Randomness.html) and [Chapter 10](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html) of the online <i>Inferential Thinking</i> textbook. \n",
    "<br>**<center>Learning Goals**\n",
    "|Area|Concept|\n",
    "|---|---|\n",
    "|Probability|Probability of outcomes including die roles and beyond|\n",
    "|Simulation |Sample the distribution|\n",
    "| - Iteration|  for i in np.arange(samples)|\n",
    "| - numpy random | random.choice() to randomly select among outcomes|\n",
    "|Conditional|Comparisons using `if` and boolean operator|\n",
    "|Boolean Operators| `==`, `!=`, `>`,`<`,`>=`,`<=`| \n",
    "\n",
    "\n",
    "\n",
    "First, set up the tests and imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "from gofer.ok import check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dungeons and Dragons and Sampling\n",
    "In the game Dungeons & Dragons, each player plays the role of a fantasy character.\n",
    "A player performs actions by rolling a 20-sided die, adding a \"modifier\" number to the roll, and comparing the total to a threshold for success. The modifier depends on her character's competence in performing the action.\n",
    "For example, suppose Alice's character, a barbarian warrior named Roga, is trying to knock down a heavy door. She rolls a 20-sided die, adds a modifier of 11 to the result (because her character is good at knocking down doors), and *succeeds if the total is greater than 15*.<br> A Medium posting discusses probability in the context of Dungeons and Dragons https://towardsdatascience.com/understanding-probability-theory-with-dungeons-and-dragons-a36bc69aec88 <br><br><img src= data/DnD.JPG height=\"200\"><br>\n",
    "#### <font color=blue> **Question 1.1.** </font>\n",
    "Write code that simulates the above process:<br>\n",
    "- Roll a 20 sided die\n",
    "- Add a modifier of +11\n",
    "- Check if the combined roll succeeds (roll + modifier > 15)\n",
    "</li>\n",
    "<br>\n",
    "<p>In other words, compute three values: the result of Alice's roll (roll_result), the result of her roll plus Roga's modifier (modified_result), and a boolean value indicating whether the action succeeded (action_succeeded). Do not fill in any of the results manually; the entire simulation should happen in code.\n",
    "Hint: A roll of a 20-sided die is a number chosen uniformly from the array make_array(1, 2, 3, 4, ..., 20). So a roll of a 20-sided die plus 11 is a number chosen uniformly from that array, plus 11.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_rolls = ...\n",
    "roll_result = ...\n",
    "modified_result = ...\n",
    "action_succeeded = ...\n",
    "\n",
    "# The next line just prints out your results in a nice way\n",
    "# once you're done.  You can delete it if you want.\n",
    "print(f\"On a modified roll of {modified_result}, Alice's action {'succeeded' if action_succeeded else 'failed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 1.2.** </font> \n",
    "Run your cell 7 times to manually estimate the chance that Alice succeeds at this action. (Don't use math or an extended simulation.). Your answer should be a fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_success_chance = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we don't know that Roga has a modifier of 11 for this action.  Instead, we observe the modified roll (that is, the die roll plus the modifier of 11) from each of 7 of her attempts to knock down doors.  We would like to estimate her modifier from these 7 numbers.<br>\n",
    "\n",
    "#### <font color=blue> **Question 1.3.** </font>\n",
    "Write a Python function called `simulate_observations`.  It should take two arguments, the modifier and num_oobservations, and it should return an array of num_observations.  Each of the numbers should be the modified roll from one simulation.  **Then**, call your function once to compute an array of 7 simulated modified rolls.  Name that array `observations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = 11\n",
    "num_observations = 7\n",
    "\n",
    "def simulate_observations(modifier, num_observations):\n",
    "    \"\"\"Produces an array of 7 simulated modified die rolls\"\"\"\n",
    "    ...\n",
    "\n",
    "observations = ...\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 1.4.** </font> \n",
    "Draw a histogram to display the *probability distribution* of the modified rolls we might see.  Check with a neighbor or a CA to make sure you have the right histogram. Carry this out again using 100 rolls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We suggest using these bins.\n",
    "roll_bins = np.arange(1, modifier+2+20, 1)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the modifier\n",
    "Now let's imagine we don't know the modifier and try to estimate it from observations.\n",
    "One straightforward (but clearly suboptimal) way to do that is to find the smallest total roll (`min()`), since the smallest roll on a 20-sided die is 1, which is corresponds to a modifier of 0. Use a random number for <i>modifier</i> to start and keep this value through the next questions. We will also generate 100 rolls based on the below unknown modifier. <br>\n",
    "#### <font color=blue> **Question 1.5.** </font>\n",
    "Using that method, estimate modifier from observations. Name your estimate min_estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = np.random.randint(1,20) # Generates a random integer modifier from 1 to 20 inclusive\n",
    "... = simulate_observations(modifier, num_observations)\n",
    "...\n",
    "min_estimate = ...\n",
    "min_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the modifier based on the mean of observations.\n",
    "#### <font color=blue> **Question 1.6.** </font>\n",
    "Figure out a good estimate based on using the mean of all the modified rolls. Then, write a function named mean_based_estimator that computes your estimate. It should take an array of modified rolls (like the array observations) as its argument and return an estimate (single number) of the modifier based on those numbers contained in the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**What is the mean of many rolls (1000's) of a 20-sided die?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean20 = ...\n",
    "mean20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_based_estimator(obs):\n",
    "    \"\"\"Estimate the roll modifier based on observed modified rolls in the array nums.\"\"\"\n",
    "    ...\n",
    "\n",
    "# Here is an example call to your function.  It computes an estimate\n",
    "# of the modifier from our  observations.\n",
    "mean_based_estimate = mean_based_estimator(observations)\n",
    "mean_based_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 1.7.** </font>\n",
    "Construct a histogram and compare to above estimates, are they consistent?\n",
    "What is your best estimate of the random modiifer based on the above, without examining the value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(..., bins = ...) # Use to plot histogram of an array of 100 modified rolls\n",
    "estimated_modifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling and GC content of DNA sequence\n",
    "DNA within a cell contains codes or sequences for the ultimate synthesis of proteins. In DNA is made up of four types of nucleotides, guanine (G), cytosine (C), adenine (A), and thymine (T) connected in an ordered sequence. These nucleotides on a single strand pair with complimentary nucleotides on a second strand, G pairs with C and A with T. Regions of DNA code for RNA which ultimately directs protein synthesis and these segments are known as genes and these segments often have higher GC content. Here we will sample 10 nuclotide segments of a DNA sequence and determine the GC content of these DNA segments. See [DNA sequnce basics](http://data-science-sequencing.github.io/Win2018/assets/lecture2/lecture2_2018.pdf) and [GC Content details](https://geneticeducation.co.in/what-is-the-importance-of-gc-content/). \n",
    "##### Our goal is to sample portions (10 nucelotides) of the sequence and determine<br> the relative content of guanine (G) and cytosine (C) to adenine (A) and thymine (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA sequence we will examine, a string\n",
    "seq = \"CGTAACAAGGTTTCCGTAGGTGAACCTGCGGAAGGATCATTGATGAGACCGTGGAATAAACGATCGAGTG \\\n",
    "AATCCGGAGGACCGGTGTACTCAGCTCACCGGGGGCATTGCTCCCGTGGTGACCCTGATTTGTTGTTGGG \\\n",
    "CCGCCTCGGGAGCGTCCATGGCGGGTTTGAACCTCTAGCCCGGCGCAGTTTGGGCGCCAAGCCATATGAA \\\n",
    "AGCATCACCGGCGAATGGCATTGTCTTCCCCAAAACCCGGAGCGGCGGCGTGCTGTCGCGTGCCCAATGA \\\n",
    "ATTTTGATGACTCTCGCAAACGGGAATCTTGGCTCTTTGCATCGGATGGAAGGACGCAGCGAAATGCGAT \\\n",
    "AAGTGGTGTGAATTGCAAGATCCCGTGAACCATCGAGTCTTTTGAACGCAAGTTGCGCCCGAGGCCATCA \\\n",
    "GGCTAAGGGCACGCCTGCTTGGGCGTCGCGCTTCGTCTCTCTCCTGCCAATGCTTGCCCGGCATACAGCC \\\n",
    "AGGCCGGCGTGGTGCGGATGTGAAAGATTGGCCCCTTGTGCCTAGGTGCGGCGGGTCCAAGAGCTGGTGT \\\n",
    "TTTGATGGCCCGGAACCCGGCAAGAGGTGGACGGATGCTGGCAGCAGCTGCCGTGCGAATCCCCCATGTT \\\n",
    "GTCGTGCTTGTCGGACAGGCAGGAGAACCCTTCCGAACCCCAATGGAGGGCGGTTGACCGCCATTCGGAT \\\n",
    "GTGACCCCAGGTCAGGCGGGGGCACCCGCTGAGTTTACGC\" # LCBO-Prolactin precursor-Bovine\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.1A.** </font>\n",
    "Run the first two code cells below to see how substrings are extracted and how a character can be counted within a substring. Use the same strategy to determine GC content as fraction of the total in the first 10 nucleotides in the larger sequence above, `seq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example A\n",
    "samplesize = 4\n",
    "# Use this short sequence in this example\n",
    "seq0 = 'GTGAAAGATT'\n",
    "# How to get a substring\n",
    "seq0[0:samplesize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example B\n",
    "# How to count the number of times 'A' appears in sequence\n",
    "seq0[0:samplesize].count('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCcount = seq[0:10].count('G') + seq[...]...\n",
    "GCfraction = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lists\n",
    "Below we assemble a list and append an additional entry, 0.7. A useful strategy in creating your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = []\n",
    "gc.append(0.8)\n",
    "gc.append(0.7)\n",
    "gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill a list with 30 random G, C, T, A nucleotides \n",
    "use iteration and `np.random.choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sim_seq = []\n",
    "nucleo = ['G','C','T','A']\n",
    "for i in np.arange(...):\n",
    "    my_sim_seq.append(np. ...)\n",
    "\n",
    "print(my_sim_seq)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.1B.** </font>\n",
    "We will define a function, `calcGC` to do the repetitive work of computing GC content fraction for each segment (samplesize) and return a list with the fraction GC for each `samplesize` segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcGC(seq, samplesize):\n",
    "    gc = []\n",
    "    for i in range(len(seq)-samplesize):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.2.** </font>\n",
    "Apply this function to our sequence above <i>seq</i> with a samplesize of 10. What is the maximum, minimum, mean, and median? Use you five number summary function from the Olympics Mini-project (Hint: the max of a list can be obtained with the max(results) and we can use np.mean(results)). Plot the results by using plt.plot(results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesize = ...\n",
    "results = ...\n",
    "maximum = ...\n",
    "minimum = ...\n",
    "median = ...\n",
    "mean = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.3.** </font> \n",
    "Now apply this function to our sequence above <i>seq</i> with a different, larger samplesize (>30) of your choosing and plot. What do you observed with the different sampling? What is the maximum, minimum, mean, and median? (Hint: the max of a list can be obtained with the max(results) and we can use np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **Question 2.3 Discussion.** </font>\n",
    "<font color='green'> Discuss your results. You just did a fairly sophisticated DNA analysis, so there should be a lot to say. For example, how did changing samplesize affect your ability to identify GC-rich DNA regions? Why are these regions so important (do a little reading). Given a year-long record of daily temperatures, how might a similar approach of varying sample size be used to distinguish seasonal temperature trends from day-to-day fluctuations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wordle and sampling\n",
    "Inspired by Medium post: https://ericlani.medium.com/determining-the-best-first-wordle-word-to-guess-using-data-b93b975a6294\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Letter frequency in sampled texts\n",
    "We will begin our study by trying to understand the frequency of certain letters by sampling texts.  We will again use Charles Darwin's book on the Origin of Species to examine the frequency of letters in this text. To do this we will need to write a function which goes through all the words and determines the counts of letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_string = open('data/darwin_origin_species.txt', encoding='utf-8').read()\n",
    "darwin_words = np.array(darwin_string.split())\n",
    "darwin_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> ****Question 3.1**.** </font> \n",
    "We will examine some details about the array of words from Darwin's Origin of Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How may words are in Darwin's Origin of Species?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the first three words and how many letters are in these first three words?** Hint: Each word has an index in the array, the 10th word would be `darwin_words[9]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darwin_words[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a for loop to step through the letters in the third word.**\n",
    "Print the lower case version of the letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in ...:\n",
    "    print(letter.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.isalpha()` : checks if character is alphanumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"b\".isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\",\".isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries\n",
    "A Python dictionary stores values in pairs, a key and a value. For example when we considered the height in meters of each of the Adirondack High Peaks in Lab 02 we had values representing the height in meters without a label. With a dictionary we could use the name of the mountain as a key with the height as a value. Below we will use a dictionary to store the number of times a letter occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADK_highpeaks = [1629,1559,1512,1501] \n",
    "ADK_highpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADK_dictionary = {'Mount Marcy':1629,'Algonquin Peak':1559,'Mount Haystack':1512,'Mount Skylight':1501}\n",
    "ADK_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADK_dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ADK_dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADK_dictionary.get('Algonquin Peak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function** to determine letter frequency in text with words split in an array as in above <i>darwin_words</i> array and return a Table with letters and their count. We will use a nice trick with a Python dictionary (see: [Python Dictionaries](https://realpython.com/python-dicts/)) as already encoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_freq(words):\n",
    "    f = {} # Create an empty dictionary to store letters and their count found in words\n",
    "    for ...:\n",
    "        for ...:\n",
    "            l = l.lower()\n",
    "            if l.isalpha(): # avoid punctuation\n",
    "                f[l] = f.get(l,0) + 1 # Using Python dictionary\n",
    "    return Table().with_columns('letters',list(f.keys()),'count',list(f.values()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now test your function with your own sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"...\"\n",
    "letter_freq(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** Apply the function to the <i>darwin_string</i> and examine the output. How many total letters in the text (Hint: use np.sum(freq.column('count')))? Now compute a new column, <i>frequency</i> which contains the fraction of each letter. What are the two most frequent letters in this sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = letter_freq(darwin_words).sort(\"letters\")\n",
    "\n",
    "total_letters = ... # How many letters\n",
    "\n",
    "freq = freq.with_columns(...).sort(\"frequency\",descending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Five letter words\n",
    "**Question 3.3** Now look at a list of 5 letter words assembled by Professor Emeritas Donald Knuth of Stanford. Use your function to determine the letter frequency and compare to above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen # Needed to read from internet\n",
    "\n",
    "url = \"https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\"\n",
    "knuth5_string=urlopen(url).read().decode('utf-8') \n",
    "knuth_words = np.array(knuth5_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply your function and compute letter frequencies\n",
    "freq = ...\n",
    "\n",
    "freq = freq.with_columns(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Oxford Dictionary\n",
    "Based on analysis of Oxford dictionary these are the letter frequencies from the dictionary. Compare the three, in the markdown below, what are the similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data/Oxford_Letter_frequency.csv\"\n",
    "letters = Table().read_table(url, header=None, names=[\"letters\",\"frequency\",\"count\"])\n",
    "letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparsion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** Let's look at 5-letter words and the frequency of each letter and compare with Oxford case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordle itself\n",
    "The New York Times hosts [Wordle](https://www.nytimes.com/games/wordle/index.html) where a 5 letter word (Wordle) is determined in six or fewer tries using clues about letters contained and letter position. We will use our new knowledge of letter frequency and Knuth's 5 letter words to come up with best letters and words to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload Knuth's words in more convenient pandas format\n",
    "url = \"https://www-cs-faculty.stanford.edu/~knuth/sgb-words.txt\"\n",
    "# Better to read with pandas\n",
    "import pandas as pd\n",
    "words_df = pd.read_csv(url, header=None, names=[\"Words\",\"value\",\"letters\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load our letter frequency, <i>freq</i>, data table from a chosen text and convert to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_df = freq.to_df() # Select table from each text above\n",
    "letters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** Devise a plan to use the collection of letter frequencies and Knuth's five letter words to order the best words to guess for Wordle? Higher letter frequency means more words with the given letter. Describe plan in text markdown only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Magic\" Wordle computation\n",
    "Takes a while, be patient.\n",
    "Can you interpret how this code is sorting Knuth's words based on our letter frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in words_df.iterrows():\n",
    "    prob = 0\n",
    "    letter_set = set()\n",
    "    for ele in row['Words']:\n",
    "        letter_set.add(ele)\n",
    "        temp_df = letters_df[letters_df[\"frequency\"].where(letters_df[\"letters\"] == ele).notnull()]\n",
    "        temp_df\n",
    "        prob += temp_df[\"frequency\"].iloc[0]\n",
    "        words_df.loc[index, [\"value\"]] = prob\n",
    "        words_df.loc[index, [\"letters\"]] = len(letter_set)\n",
    "        \n",
    "words_df       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four letter words are included now we will select only five letter words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.where(words_df[\"letters\"]==5.0).sort_values(by='value',ascending=False).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6**\n",
    "#### Compare top word given based on Darwin's text, Knuth's letter frequency, and the Oxford Dictionary.\n",
    "\n",
    "Top words for Wordle:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete and tally your score.\n",
    "Submit .html and .ipynb of completed laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "total = 11\n",
    "checks = ['1.1','1.2', '1.3', '1.5', '1.6', '1.7', '2.1', '2.2', '3.1', '3.2','3.3']\n",
    "for x in checks:\n",
    "    print('Testing question {}: '.format(x))\n",
    "    g = check('tests/q{}.py'.format(x))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nice work \",name, user)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
