{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 07-STEM-UP Machine Learning and prediction\n",
    "Elements of Data Science   \n",
    "In this laboratory we will use training data to predict outcomes. We will first test these ideas using an Old Faithful data set. Next we will look at data on the iris flower to classify iris' based on sepal width and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your_name = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from training data\n",
    "A key concept in machine learning is using a subset of a dataset to train an algorithm to make estimates on a separate set of test data. The quality of the machine learning and algorithm can be assesed based on the accuracy of the predictions made on test data. Many times there are also parameters sometimes termed hyper-parameters which can be optimized through an iterative approach on test or validation data. In practice a dataset is randomly split into training and test sets using sampling. \n",
    "### k nearest neighbor\n",
    "We will examine one machine learning algorithm in the laboratory, k nearest neighbor. Many of the concepts are applicable to the broad range of machine learning algorithms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import statements\n",
    "# These lines load the tests. \n",
    "from gofer.ok import check\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "#from IPython.display import Image\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "# Fix for datascience collections Iterable\n",
    "import collections as collections\n",
    "import collections.abc as abc\n",
    "collections.Iterable = abc.Iterable\n",
    "!pip install jupyterquiz\n",
    "from jupyterquiz import display_quiz\n",
    "import json\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How Faithful is Old Faithful? \n",
    "\n",
    "(Note: clever title comes from [here](http://web.pdx.edu/~jfreder/M212/oldfaithful.pdf).)\n",
    "\n",
    "Old Faithful is a geyser in Yellowstone National Park in the central United States.  It's famous for erupting on a fairly regular schedule.  You can see a video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the curious: this is how to display a YouTube video in a\n",
    "# Jupyter notebook.  The argument to YouTubeVideo is the part\n",
    "# of the URL (called a \"query parameter\") that identifies the\n",
    "# video.  For example, the full URL for this video is:\n",
    "#   https://www.youtube.com/watch?v=wE8NDuzt8eg\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"wE8NDuzt8eg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of Old Faithful's eruptions last longer than others.  When it has a long eruption, there's generally a longer wait until the next eruption.\n",
    "\n",
    "If you visit Yellowstone, you might want to predict when the next eruption will happen, so you can see the rest of the park and come to see the geyser when it erupts.  To predict one variable from another, the first step is to understand the association between them.\n",
    "\n",
    "The dataset has one row for each observed eruption.  It includes the following columns:\n",
    "- **duration**: Eruption duration, in minutes\n",
    "- **wait**: Time between this eruption and the next, also in minutes\n",
    "\n",
    "Run the next cell to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"data/faithful.csv\")\n",
    "faithful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### k nearest neighbor regression\n",
    "We will use the k nearest neighbor algorithm to make predictions of wait time in minutes following an eruption duration of a given number of minutes (independent variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"data/faithful.csv\")\n",
    "faithful.scatter(0, 1, fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 1* \n",
    "Use the datascience .split(n) Table method to split the dataset into 80% training and 20% test. The argument for .split(n) method,n, needs to be an integer. [See datascience documentation](https://datascience.readthedocs.io/en/master/_autosummary/datascience.tables.Table.split.html#datascience.tables.Table.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainf, testf = ....split(int(faithful.num_...*0.8))\n",
    "print(trainf.num_rows, 'training and', testf.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor concept\n",
    "The training examines the chreacteristics of *k* nearest neighbors to the data point for which a prediction will be made. Nearness is measured using several different [metrics](https://www.nhm.uio.no/english/research/infrastructure/past/help/similarity.html) with Euclidean distance being a common one for numerical attributes.  \n",
    "Euclidean distance:   \n",
    "1-D $$ d(p,q) = \\sqrt{(p-q)^{2}} $$   \n",
    " 2-D $$ d(p,q) = \\sqrt{(p_1-q_1)^{2}+(p_2-q_2)^{2}} $$\n",
    " \n",
    " For multiple points (rows):\n",
    " 2-D $$ d(p,q) = \\sum{{\\sqrt{((p_1-q_1)^{2}+(p_2-q_2)^{2}}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try different attribute values in the following 2D Euclidean distance example code below to get a feel for the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to compute an Euclidean distance between two 2-D points\n",
    "d_p_q = np.sqrt(sum((make_array(2,3)-make_array(4,3))**2))\n",
    "d_p_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get values from Table row as an array as is done in row_distance. Note in the faithful data case we will only consider the duration column in nearest neighbor computation but in examples below we will use a 2-D array of attributes with the iris data and a 10-D array in the chemistry and molecular acidity case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_array = np.array(faithful.row(0))\n",
    "f_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A couple quick review questions about nearest neighbor below, select the best answer (multiple tries ok). Execute the below cell to reveal the self-check quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions=json.load(file)    \n",
    "display_quiz(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 2* \n",
    "Define a function which is the Euclidean distance between two values. Use the last two example code cells above as inspiration. This is where we will compute the distance between two *duration* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt1, pt2):\n",
    "    \"\"\"The distance between two points, represented as arrays.\"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q2.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest of the nearest neighbor algorithm\n",
    "Execute these cells to create the complete algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_distance(row1, row2):\n",
    "    \"\"\"The distance between two rows of a table.\"\"\"\n",
    "    return distance(np.array(row1), np.array(row2)) # Need to convert rows into arrays\n",
    "\n",
    "def distances(training, example, output):\n",
    "    \"\"\"Compute the distance from example for each row in training.\"\"\"\n",
    "    dists = []\n",
    "    attributes = training.drop(output)\n",
    "    for row in attributes.rows:\n",
    "        dists.append(row_distance(row, example))\n",
    "    return training.with_column('Distance', dists)\n",
    "\n",
    "def closest(training, example, k, output):\n",
    "    \"\"\"Return a table of the k closest neighbors to example.\"\"\"\n",
    "    return distances(training, example, output).sort('Distance').take(np.arange(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 3*\n",
    "Take an example row from the test data (testf), drop the prediction column and use the closest function to see the top 10 closest points to the target in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = ....drop(1)....\n",
    "example_row   # This should display data contained in selected row in testf table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ... # Number of nearest neighbors\n",
    "closest(...,example_row,...,'wait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 4*\n",
    "Predict the value for this row using the defined predict_nn function below and compare to the value reported for wait in the test data. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(example):\n",
    "    \"\"\"Return the majority class among the k nearest neighbors.\"\"\"\n",
    "    k = 10\n",
    "    return np.average(closest(trainf, example, k , 'wait').column('wait'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionf = ...  # This is the value predicted for wait using the average of the k nearest neighbors in the test set\n",
    "actual = ...\n",
    "print(predictionf,actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q4.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 5* Predictions\n",
    "Now we will make predictions for the whole data set using the apply Table method. We will then look at the root mean squared error (RMSE) for the nearest neighbor fit and a scatter plot. Try adjusting the value of k in the predict_nn function to see it's effect on the quality of fit by rerunning these cells. Are the predicted points in a **perfect** straight line, why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf = testf.with_columns(\"predict\",testf.apply(predict_nn,\"duration\"))\n",
    "nn_test_predictions = testf.column(\"predict\")\n",
    "test_wait = testf.column(\"wait\")\n",
    "rmse_nn = np.mean((test_wait - nn_test_predictions) ** 2) ** 0.5\n",
    "\n",
    "print('Test set RMSE for nearest neighbor regression:', round(rmse_nn,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testf.scatter(\"duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Answer here  </font>\n",
    "***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classify iris data with machine learning\n",
    "Next we will take on the problem of classifying iris data into three categories, setosa, versicolor, and virginica. Here we will also learn the basics of the k nearest neighbor algorithm.\n",
    "\n",
    "The first data set we will look at consists of 50 samples from three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured including the length and the width of the sepals and petals, in centimeters for each observation.\n",
    "<br><center><img src='iris.png' width=150 height=150><br>Iris stainglass, J.R. Smith</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "# Load iris data\n",
    "iris = datasets.load_iris()\n",
    "# We only take the first two features. \n",
    "iris_table = Table().with_columns(\"Name\",iris.target,iris.feature_names[0],iris.data[:,0],iris.feature_names[1],iris.data[:,1])\n",
    "iris_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 6*\n",
    "Train and test split the iris_table @ 80% as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i, test_i = iris_table.split(int...\n",
    "print(train_i.num_rows, 'training and', test_i.num_rows, 'test instances.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 7* \n",
    "With classification we need to use training data to decide how to classify data given a set of attributes, sepal length and sepal width in this case. Create a function which returns the majority classification among three possibilities in \"Name\" coded as 0, 1, 2 (setosa, versicolor, and virginica respectively). The `and` below combines two conditionals. For example,  (twos > ones) and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(topkclasses):\n",
    "    twos = topkclasses.where('Name', are.equal_to(2)).num_rows\n",
    "    ones = topkclasses.where...\n",
    "    zeros = ...\n",
    "    # Now test to see what the majority name for each k class\n",
    "    if ... and ...: # Hint: (twos > ones) and (twos > zeros)\n",
    "        return 2\n",
    "    elif ... and ...: # Hint: (ones > twos) and (... > zeros)\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(training, new_point, k):\n",
    "    closestk = closest(training, new_point, k,\"Name\")\n",
    "    topkclasses = closestk.select('Name')\n",
    "    return majority(topkclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = 21\n",
    "print(\"Prediction: \",classify(train_i,example_row,test_row),\" Actual: \",test_i.select(\"Name\").row(test_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train, test_attributes, k):\n",
    "    pred = []\n",
    "    for i in np.arange(test_attributes.num_rows):\n",
    "        pred.append(classify(train,test_attributes.row(i),k))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 8*\n",
    "Make a new table called prediction which includes original columns of test Table but also includes a \"predict\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ...\n",
    "prediction = test_i.with_columns(\"predict\",...)\n",
    "prediction.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision outcomes for test set\n",
    "#### *Question 9* \n",
    "Use above prediction Table to make a scatter plot of the color coded predictions based on the tweo attributes(use colors=\"predict\" in scatter plot after specifying x and y axis based on attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.drop(\"Name\").scatter(...,...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy plot showing color coded decision boundaries\n",
    "We can make a more informative plot by predicting on a grid of attribute values as shown below. Seaborn is an add-on to the Matplotlib plotting we have been using which provides more control of plotting. Execute (this may take a minute+) and study the below input and resulting output for your information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colors(iris, y, cmap):\n",
    "    colors = []\n",
    "    cdict = {'setosa':0, 'virginica':2, 'versicolor':1}\n",
    "    for x in iris.target_names[y]:\n",
    "        colors.append(cmap[cdict[x]])\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = .1  # step size in the mesh\n",
    "k = 10\n",
    "x_min, x_max = iris.data[:, 0].min() - 1, iris.data[:, 0].max() + 1\n",
    "y_min, y_max = iris.data[:, 1].min() - 1, iris.data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "## Create a grid of predictions in a Table\n",
    "attribute_grid = Table().with_columns(iris.feature_names[0],np.c_[xx.ravel(), yy.ravel()][:,0],iris.feature_names[1],np.c_[xx.ravel(), yy.ravel()][:,1])\n",
    "\n",
    "Z = np.array(predict(train_i,attribute_grid,k))\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot the test points but convert to numpy arrays\n",
    "predictions = prediction.column('predict')\n",
    "attribute1 = prediction.column(1)\n",
    "attribute2 = prediction.column(2)\n",
    "plt.scatter(x=attribute1, y=attribute2, c = make_colors(iris, predictions, cmap_bold), alpha=1.0, edgecolor=\"black\")\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i')\"\n",
    "              % (k))\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit learn\n",
    "[Scikit learn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors) is a standard state of the art machine learning library. For demonstration purposes execute the below commands to classify  and generate a comparable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(k) # Initiate the classifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data[:,:2], iris.target, random_state=22) #  scikit split\n",
    "# Now fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = .1  # step size in the mesh\n",
    "x_min, x_max = iris.data[:, 0].min() - 1, iris.data[:, 0].max() + 1\n",
    "y_min, y_max = iris.data[:, 1].min() - 1, iris.data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "cmap_bold = ['darkorange', 'c', 'darkblue']\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "y = y_test\n",
    "plt.scatter(x=x_test[:, 0], y=x_test[:, 1], c = make_colors(iris, y, cmap_bold),\n",
    "                    alpha=1.0, edgecolor=\"black\")\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i')\"\n",
    "              % (k))\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Question 10* \n",
    "Comment on the quality of the predictions by <font color='blue'>\n",
    "1. <font color='green'>Your nearest neighjbor algorithm \n",
    "2. <font color='green'>scikit learn \n",
    "3. <font color='green'>Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Answers here </font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All finished...\n",
    "Run checks and submit .html and .ipynb files after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "correct = 0\n",
    "checks = [1,2,3,4,6,7,8]\n",
    "total = len(checks)\n",
    "for x in checks:\n",
    "    print('Testing question {}: '.format(str(x)))\n",
    "    g = check('tests/q{}.py'.format(str(x)))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print('Failed')\n",
    "        display(g)\n",
    "\n",
    "print('Grade:  {}'.format(str(correct/total)))\n",
    "print(\"Nice work \",Your_name)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
