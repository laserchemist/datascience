{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Variance of Sample Means and Correlation\n",
    "\n",
    "In this lab we will learn about [the variance of sample means](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html) as well as ways to understand and quantify [the association between two variables](https://inferentialthinking.com/chapters/15/1/Correlation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import statements\n",
    "# These lines load the tests. \n",
    "from gofer.ok import check\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How Faithful is Old Faithful? \n",
    "\n",
    "(Note: clever title comes from [here](http://web.pdx.edu/~jfreder/M212/oldfaithful.pdf).)\n",
    "\n",
    "Old Faithful is a geyser in Yellowstone National Park in the central United States.  It's famous for erupting on a fairly regular schedule.  You can see a video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For the curious: this is how to display a YouTube video in a\n",
    "# Jupyter notebook.  The argument to YouTubeVideo is the part\n",
    "# of the URL (called a \"query parameter\") that identifies the\n",
    "# video.  For example, the full URL for this video is:\n",
    "#   https://www.youtube.com/watch?v=wE8NDuzt8eg\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"wE8NDuzt8eg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Some of Old Faithful's eruptions last longer than others.  When it has a long eruption, there's generally a longer wait until the next eruption.\n",
    "\n",
    "If you visit Yellowstone, you might want to predict when the next eruption will happen, so you can see the rest of the park and come to see the geyser when it erupts.  To predict one variable from another, the first step is to understand the association between them.\n",
    "\n",
    "The dataset has one row for each observed eruption.  It includes the following columns:\n",
    "- **duration**: Eruption duration, in minutes\n",
    "- **wait**: Time between this eruption and the next, also in minutes\n",
    "\n",
    "Run the next cell to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful = Table.read_table(\"faithful-new.csv\")\n",
    "faithful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 1.** </font>\n",
    "\n",
    "Make a scatter plot of the data.  It's conventional to put the column we will try to predict on the vertical axis and the other column corresponding to the independent variable on the horizontal axis. The predictor column is the independent or often labeled x variable. First we will make a string, *predictor_col*, which contains the label as a string of the predictor column (\"duration\" or \"wait\"). Next we will make a scatter plot of the Old Faithful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_col = 'duration' # This is the column label as a string of the predictor column or independent x variable\n",
    "\n",
    "# Supply the two column names\n",
    "faithful.scatter(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: To plot a scatter plot you need arrays from columns of data\n",
    "See example below to examine the Philadelphia Phillies winning percentage, `PCT`, as a function of year, `YEAR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE DATA AND SCATTER PLOT\n",
    "exampledata = Table().with_columns( \n",
    "     'YEAR', np.arange(2013,2023,1), \n",
    "     'PCT', make_array(.451,.451,.389,.438,.407,.494,.500,.467,.506,.537)\n",
    ")\n",
    "exampledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The .column() method returns the data from the specified column as an array\n",
    "# For example:\n",
    "exampledata.column('YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use each column as an array to plot\n",
    "plt.scatter(exampledata.column('YEAR'),exampledata.column('PCT'),color=\"red\") \n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Winning %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Line\n",
    "We can fit the observed trend using linear regression. We seek to understand the fundamental priciples behind this important manner of  fitting data. We will learn several ways to fit a line in this class. Let's start by using numpy's polyfit() function that fits a polynomial to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate equation for regression line\n",
    "# Note: np.polyfit() fits a polynomial function to the data. The format of the function call is:\n",
    "# np.polyfit(x_data, y_data, polynomial_order\n",
    "# A polynomial of order 1 is a line; order 2 is a parabola; order 3 is a cubic, and so forth.\n",
    "\n",
    "# The function returns two values\n",
    "slope, intercept = np.polyfit(exampledata.column('YEAR'),exampledata.column('PCT'), 1)\n",
    "\n",
    "print('The slope of the line is:', slope)\n",
    "print('The intercept is:', intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the slope and intercept to add the best-fit straight line\n",
    "Now that we have the slope and intercept, we can use our x-values ('YEAR') to calculate the fitted y-values, which are the predicted values of 'PCT' given a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = slope * exampledata.column('YEAR') + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the scatter plot\n",
    "plt.scatter(exampledata.column('YEAR'),exampledata.column('PCT'),color=\"red\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Winning %\")\n",
    "\n",
    "# add the annotation, xy gives the position on the plot for the start of the text\n",
    "# you can try changing it to move the annotation around on the plot\n",
    "# the f-string formatting inserts the variable values into the string and the \":.2f\"\n",
    "# formats the floating point numbers to show only two places after the decimal\n",
    "plt.annotate(f\"Slope: {slope:.2f}, Intercept: {intercept:.2f}\", xy=(2014, 0.52))\n",
    "\n",
    "# add the regression line to plot\n",
    "plt.plot(exampledata.column('YEAR'), y_predict, color=\"blue\", linewidth=3, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second example: Organic alcohol molecular weight and carbon chain length and their affect on boiling point\n",
    "- Hypothesis: As alcohol molecular weight increases boiling point will increase due to greater dispersion forces\n",
    "- Null hypothesis: Molecular weight does not affect boiling point, only random variation. Slope randomly varies about zero for different molecular weights <br>\n",
    "Two example butanol isomers are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"CCCCO\") #n-butanol; Molecular Weight = 74.12 g/mol 117.7°C = 391 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(\"CC(C)CO\") #iso-butanol; Molecular Weight = 74.12 g/mol; bp = 108 °C = 381 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data_file = 'ROH_data.csv'\n",
    "ROH_data = Table().read_table(data_file)\n",
    "ROH_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot molecular weight vs boiling point. Is there a relationship?\n",
    "# Make the size of the dots proportional to the number of carbon atoms (uses the s= option)\n",
    "plt.scatter(ROH_data['MW'], ROH_data['bp'], color = 'brown', s=10*ROH_data['carbons'])\n",
    "plt.xlabel('MW [g/mol]')\n",
    "plt.ylabel('bp [deg K]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Line\n",
    "We can fit the observed trend using linear regression. We seek to understand the fundamental priciples behind this important manner of  fitting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(ROH_data['MW'],ROH_data['bp'],color = 'brown',s=10*ROH_data['carbons']) # need to use each column as an array to plot\n",
    "plt.xlabel('MW [g/mol]')\n",
    "plt.ylabel('bp [K]')\n",
    "\n",
    "# Here is a second way to fit a line -- using the linregress function in the scipy.stats module.\n",
    "# This approach has the advantage of returning not just the slope and intercept, some measures of how well\n",
    "# the linear regression model fits. The R-squared value is 1 for a perfect fit; zero for no linear correlation.\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(ROH_data['MW'],ROH_data['bp'])\n",
    "\n",
    "# annotate with slope, intercept and r-squared value\n",
    "# Notice two formatting tricks:\n",
    "# \\n insert a line break (newline) so R-squared appears on the next line\n",
    "# $R^2$ inserts some markdown fomatting. Anything inclosed in dollar signs is interpreted as an equation\n",
    "plt.annotate(\n",
    "    f\"Slope: {slope:.2f}, Intercept: {intercept:.2f} \\n $R^2$: {r_value:0.3}\",\n",
    "    xy=(35, 510),\n",
    ")\n",
    "\n",
    "# Use our fit to predict boiling points based on this linear model\n",
    "bp_predict = slope * ROH_data.column('MW') + intercept\n",
    "\n",
    "# add a regression line to plot\n",
    "plt.plot(ROH_data['MW'], bp_predict, color=\"blue\", linewidth=3, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Old Faithful data</font>\n",
    "#### Now try to plot the `faithful` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithful.stats() # Helpful check on data, not neccessary in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot\n",
    "plt.scatter(faithful.column(predictor_col), faithful.column('wait'))\n",
    "plt.xlabel(\"duration\")\n",
    "plt.ylabel(\"wait\")\n",
    "plt.savefig(\"scatter.png\") # Helpful way to save figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Now try yourself, plot the reverse `wait`  versus  `duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(... , ...)\n",
    "plt.savefig(\"scatter_reverse.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 2.** </font>\n",
    "\n",
    "Look at the scatter plot. Are eruption duration and waiting time roughly linearly related?  Is the relationship positive, as we claimed earlier?  You may want to consult [the textbook chapter 15](https://inferentialthinking.com/chapters/15/1/Correlation.html#the-correlation-coefficient) for the definition of \"linearly related.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q2_answer = '''\n",
    "...\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check('tests/q2_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard units makes the analysis of the relationship between duration and wait more straightforward. \n",
    "First, we'll plot the data in standard units.  Recall that, if `nums` is an array of numbers, then\n",
    "\n",
    "    (nums - np.mean(nums)) / np.std(nums)\n",
    "\n",
    "is an array of those numbers in standard units. We subtract the average value and divide by the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 3.** </font>\n",
    "Compute the mean and standard deviation of the eruption durations and waiting times.  **Then** create a table called `faithful_standard` containing the eruption durations and waiting times in standard units.  (The columns should be named `\"duration (standard units)\"` and `\"wait (standard units)\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# We need these value to standarize the data\n",
    "duration_mean = ...\n",
    "duration_std = ...\n",
    "wait_mean = ...\n",
    "wait_std = ...\n",
    "\n",
    "# Add two stadardized data columns to the table\n",
    "faithful_standard = Table().with_columns(\n",
    "    \"duration (standard units)\", ...,\n",
    "    \"wait (standard units)\", ...)\n",
    "faithful_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q3.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 4.** </font>\n",
    "Plot the data again, but this time in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review from above how plot a scatter plot\n",
    "plt.scatter(faithful_standard.column(...), ...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this plot looks exactly the same as the last one!  The data really are different, but the axes are scaled differently.  The method `scatter` scales the axes so the data fill up the available space.  So it's important to read the ticks on the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 5.** </font>\n",
    "\n",
    "Among the following numbers, which would you guess is closest to the correlation between eruption duration and waiting time in this dataset?\n",
    "\n",
    "* -1\n",
    "* 0\n",
    "* 1\n",
    "\n",
    "Assign your answer to `closest_correlation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_correlation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q5.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 6.** </font>\n",
    "Compute the correlation `r`.  *Hint:* Use `faithful_standard`.  Section [15.1.2](https://inferentialthinking.com/chapters/15/1/Correlation.html#calculating-r) explains how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ...\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q6.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The regression line\n",
    "Recall that the correlation is the slope of the regression line when the data are put in standard units.\n",
    "\n",
    "The next cell plots the regression line in standard units:\n",
    "\n",
    "$$\\text{waiting time (standard units)} = r \\times \\text{eruption duration (standard units)}.$$\n",
    "\n",
    "Then, it plots the original data again, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_and_line(dataset, x, y, point_0, point_1):\n",
    "    \"\"\"Makes a scatter plot of the dataset, along with a line passing through two points. x and y are strings containing column labels\"\"\"\n",
    "    xdata = dataset.column(x)\n",
    "    ydata = dataset.column(y)\n",
    "    plt.scatter(xdata, ydata, label=\"data\")\n",
    "    xs, ys = zip(point_0, point_1)\n",
    "    plt.plot(xs, ys, label=\"regression line\")\n",
    "    plt.legend(bbox_to_anchor=(1.5, 0.8))\n",
    "\n",
    "\n",
    "plot_data_and_line(\n",
    "    faithful_standard,\n",
    "    \"duration (standard units)\",\n",
    "    \"wait (standard units)\",\n",
    "    [-2, -2 * r],\n",
    "    [2, 2 * r],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you take a point in standard units and convert it back to original units?  We'd have to \"stretch\" its horizontal position by `duration_std` and its vertical position by `wait_std`.\n",
    "\n",
    "That means the same thing would happen to the slope of the line.\n",
    "\n",
    "Stretching a line horizontally makes it less steep, so we divide the slope by the stretching factor.  Stretching a line vertically makes it more steep, so we multiply the slope by the stretching factor.\n",
    "\n",
    "### <font color=blue> **Question 7.** </font>\n",
    "What is the slope of the regression line in original units?\n",
    "\n",
    "(If the \"stretching\" explanation is unintuitive, consult section [15.2.5](https://inferentialthinking.com/chapters/15/2/Regression_Line.html#the-equation-of-the-regression-line) in the textbook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = ...\n",
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the regression line passes through the point `(duration_mean, wait_mean)`.  You might recall from high-school algebra that the equation for the line is therefore:\n",
    "\n",
    "$$\\text{waiting time} - \\verb|wait_mean| = \\texttt{slope} \\times (\\text{eruption duration} - \\verb|duration_mean|)$$\n",
    "\n",
    "After rearranging that equation slightly, the intercept turns out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = slope * (-duration_mean) + wait_mean\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q7.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 7. Discussion** </font>\n",
    "Based on your regression analysis, if you were a ranger at the park and a tourist just witnessed an eruption lasting 4 minutes, when whould you tell them to come back so as not to miss the next one? Explain your reasoning. How would you account for the linear model not being a perfect fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q7_answer = '''\n",
    "...\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check('tests/q7_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Geezers erupt without warning cartoon](geezers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variability of the Sample Mean\n",
    "\n",
    "By the Central Limit Theorem, the probability distribution of the mean of a large random sample is roughly normal. The bell curve is centered at the population mean. Some of the sample means are higher, and some lower, but the deviations from the population mean are roughly symmetric on either side, as we have seen repeatedly. Formally, probability theory shows that the sample mean is an unbiased estimate of the population mean.\n",
    "\n",
    "In our simulations, we also noticed that the means of larger samples tend to be more tightly clustered around the population mean than means of smaller samples. In this section, we will quantify the variability of the sample mean and develop a relation between the variability and the sample size.\n",
    "\n",
    "Let's take a look at the salaries of employees of the City of San Francisco in 2014. The mean salary reported by the city government was about $75463.92."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "salaries = Table.read_table('sf_salaries_2014.csv').select(\"salary\")\n",
    "salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice again, the use of .column() to extract the data as an array from a column in the\n",
    "# table before applying the numpy function mean()\n",
    "salary_mean = np.mean(salaries.column('salary'))\n",
    "salary_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a histogram and plot the location of the average value\n",
    "salaries.hist('salary', bins=np.arange(0, 300000+10000*2, 10000))\n",
    "plt.scatter(salary_mean, 0, marker='^', color='red', s=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 8.** </font>\n",
    "Clearly, the population does not follow a normal distribution. Keep that in mind as we progress through these exercises.\n",
    "\n",
    "Let's take random samples and look at the probability distribution of the sample mean. As usual, we will use simulation to get an empirical approximation to this distribution.\n",
    "\n",
    "We will define a function `simulate_sample_mean` to do this, because we are going to vary the sample size later. The arguments are the name of the table, the label of the column containing the variable, the sample size, and the number of simulations.\n",
    "\n",
    "Complete the function `simulate_sample_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Empirical distribution of random sample means\"\"\"\n",
    "\n",
    "def simulate_sample_mean(table, label, sample_size, repetitions):\n",
    "    \n",
    "    # Create an empty list to hold simulation results\n",
    "    means = []\n",
    "\n",
    "    # Loop over the simulations\n",
    "    for i in np.arange(repetitions):\n",
    "        #select a the column and sample it\n",
    "        new_sample = ...\n",
    "        # calculate the mean of the selected sample\n",
    "        new_sample_mean = ...\n",
    "        # append this to the list of means\n",
    "        ...\n",
    "\n",
    "    # Put the simulation results in a data table\n",
    "    sample_means = Table().with_column('Sample Means', means)\n",
    "    \n",
    "    # Display empirical histogram and print all relevant quantities – don't change this!\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(means, bins=20)\n",
    "    plt.xlabel('Sample Means')\n",
    "    plt.title('Sample Size ' + str(sample_size))\n",
    "    \n",
    "    textstr = '\\n'.join((\n",
    "    r'$\\mathrm{Sample  Size}=%.2f$' % (sample_size, ),\n",
    "    r'$\\mathrm{Population  Mean}=%.2f$' % (np.mean(table.column(label)), ),\n",
    "    r'$\\mathrm{Average Of Sample Means}=%.2f$' % (np.mean(means), ), \n",
    "    r'$\\mathrm{Population SD}=%.2f$' % (np.std(table.column(label)), ),\n",
    "    r'$\\mathrm{SD Of Sample Means}=%.2f$' % (np.std(means), )))\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.95, 0.75, textstr, transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q8.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 9.** </font>\n",
    "In the following cell, we will create a sample of size 100 from the salaries table and graph it using our new `simulate_sample_mean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sample_size = simulate_sample_mean(salaries, 'salary', 100, 10000) \n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following two cells, simulate the mean of a random sample of 400 salaries and 625 salaries, respectively. In each case, perform 10,000 repetitions of each of these processes. Don't worry about the `plots.xlim` line – it just makes sure that all of the plots have the same x-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "...\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "...\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the Central Limit Theorem in action – the histograms of the sample means are roughly normal, even though the histogram of the salaries themselves is far from normal.\n",
    "\n",
    "We can also see that each of the three histograms of the sample means is centered very close to the population mean. In each case, the \"average of sample means\" is very close to the population mean. Both values are provided in the printout above each histogram. As expected, the sample mean is an unbiased estimate of the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 10.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll look at what happens when we take a fixed sample size, then bootstrap from it with different numbers of resamples. How does the distribution of the resampled means change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 500)\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 1000)\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 5000)\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_sample_mean(salaries, 'salary', 100, 10000)\n",
    "plt.xlim(50000, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the variable `bootstrap_sampled_SD` to the integer corresponding to your answer to the following prediction question:\n",
    "\n",
    "When I increase the number of bootstrap samples that I take, for a fixed sample size, the SD of my sample mean will...\n",
    "\n",
    "1. Increase\n",
    "2. Decrease\n",
    "3. Stay about the same\n",
    "4. Vary widly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sampled_SD = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q10.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 10 discussion.** </font>\n",
    "What did you notice about the sample means of the four bootstrapped samples above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q10_answer = '''\n",
    "...\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check('tests/q10_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 11.** </font>\n",
    "Next, let's think about how the relationships between population SD, sample SD, and SD of sample means change with varying sample size. Which of the following is true? Again, assign the variable `pop_vs_sample` to the integer corresponding to your answer. To gain some intuition, you can run the simulation cells below.\n",
    "\n",
    "1. Sample SD gets smaller with increasing sample size, SD of sample means gets smaller with increasing sample size\n",
    "2. Sample SD gets larger with increasing sample size, SD of sample means stays the same with increasing sample size\n",
    "3. Sample SD becomes more consistent with population SD with increasing sample size, SD of sample means gets smaller with increasing sample size\n",
    "4. Sample SD becomes more consistent with populatoin SD with increasing sample size, SD of smaple means stays the same with increasing sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_vs_sample = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check('tests/q11.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens. First, we calculate the population SD so that we can compare the SD of each sample to the SD of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sd = np.std(salaries.column(\"salary\"))\n",
    "pop_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then test how a small sample behaves. Run the following cells multiple times to see how the SD of the sample changes from sample to sample. Adjust the histograms bins as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_10 = salaries.sample(10)\n",
    "sample_10.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_10.column(\"salary\")))\n",
    "means = simulate_sample_mean(sample_10, 'salary', 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_200 = salaries.sample(200)\n",
    "sample_200.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_200.column(\"salary\")))\n",
    "means = simulate_sample_mean(sample_200, 'salary', 200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1000 = salaries.sample(1000)\n",
    "sample_1000.hist(\"salary\")\n",
    "print(\"Sample SD: \", np.std(sample_1000.column(\"salary\")))\n",
    "means = simulate_sample_mean(sample_1000, 'salary', 1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this trend. Below, you will see how the average absolute error of SD from the population changes with sample size (N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it!\n",
    "\n",
    "# create an empty array\n",
    "sample_n_errors = make_array()\n",
    "\n",
    "# loop over sample sizes from 10 to 200 in steps of 10\n",
    "for i in np.arange(10, 200, 10):\n",
    "    sample_n_errors = np.append(\n",
    "        sample_n_errors,\n",
    "        np.average(\n",
    "            [\n",
    "                # This list comprehension generates 100 sample standard deviations for each sample size i\n",
    "                abs(np.std(salaries.sample(i).column(\"salary\")) - pop_sd)\n",
    "                for d in np.arange(100)\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "# creates a table with two columns and plots the result\n",
    "Table().with_columns(\n",
    "    \"Average absolute error in SD\", sample_n_errors, \"N\", np.arange(10, 200, 10)\n",
    ").plot(\"N\", \"Average absolute error in SD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that the distribution of means gets spiker, and that the distribution of the sample increasingly looks like the distribution of the population as we get to larger sample sizes. \n",
    "\n",
    "### <font color=blue> **Question 11 discussion.** </font>\n",
    "Is there a relationship between the sample size and absolute error in standard deviation? Identify this relationship – if you're having trouble, take a look at this [section](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html) in our textbook about the variability of sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q11_answer = '''\n",
    "...\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check('tests/q11_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> **Question 12.** </font>\n",
    "\n",
    "At the end of each lab, please include a reflection. \n",
    "* How did this lab go? \n",
    "* Are you confident you could fit a line to a new data set?\n",
    "* Were there questions you found especially challenging you would like your instructor to review in class? \n",
    "* How long did the lab take you to complete?\n",
    "\n",
    "Share your feedback so we can continue to improve this class!\n",
    "\n",
    "**Insert a markdown cell below this one and write your reflection on this lab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q12_answer = '''\n",
    "...\n",
    "...\n",
    "...\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check('tests/q12_open_ended.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're finished with lab 8! In order to successfully submit your assignment, follow these steps...\n",
    "- Before you do anything, **Save Notebook** from the `File` menu. Please do this first before running the cell below,\n",
    "- **run all the tests and verify that they all pass and run very last cell** (below), \n",
    "- **Review the notebook one last time** If you make any changes, please **Save** again.\n",
    "- Download as an an .ipynb file and Save nd Export as an .html file and submit both on Canvas! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import check\n",
    "\n",
    "correct = 0\n",
    "checks = [1, 3, 5, 6, 7, 8, 10, 11]\n",
    "checks = [\n",
    "    1,\n",
    "    \"2_open_ended\",\n",
    "    3,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    \"7_open_ended\",\n",
    "    8,\n",
    "    10,\n",
    "    \"10_open_ended\",\n",
    "    11,\n",
    "    \"11_open_ended\",\n",
    "    \"12_open_ended\"\n",
    "]\n",
    "total = len(checks)\n",
    "for x in checks:\n",
    "    print(\"Testing question {}: \".format(str(x)))\n",
    "    g = check(\"tests/q{}.py\".format(str(x)))\n",
    "    if g.grade == 1.0:\n",
    "        print(\"Passed\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(\"Failed\")\n",
    "        display(g)\n",
    "\n",
    "print(\"Grade:  {}\".format(str(correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nice work \",name, user)\n",
    "import time;\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "print(\"Submitted @ \", localtime)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "course": "8x",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "lab": "lab01",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "section": "3",
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
