{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project Datasets Spring 2024 \n",
    "\n",
    "### Your group has been assigned one of the following data sets.\n",
    "This notebook contains:\n",
    "* The code to load each of the data sets\n",
    "* References to the source and possible metadata\n",
    "* Data cleaning issues to consider\n",
    "* One or two ideas for relationships to explore, but do not feel constrained -- explore the data use your imagination to find other possibilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set 1: Ecological Footprint \n",
    "This dataset measures the amount of ecological resources are used from each country in the years 1961 to 2016.  More information can be found at: https://data.world/footprint/nfa-2019-edition\n",
    "\n",
    "This data set appears to be clean, but there is a lack of metadata:\n",
    "\n",
    "No units are provided. I believe areas are in hectares, and carbon is in metric tons.\n",
    "Qscore is explained here: https://www.footprintnetwork.org/data-quality-scores/\n",
    "\"total\" column is not explained, but I think it is the total area (ha).\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "* There are missing values in some of the columns.\n",
    "* The \"country\" field includes \"World,\" as a country, which could confound statistics.\n",
    "* \"forest_land\" has both numbers and numbers in quotes that read in as strings.\n",
    "* There is no \"total land\" column to put areas in perspective.\n",
    "\n",
    "### Possible Hypothesis to Test:\n",
    "The changes in land use over time could be interesting to investigate. China is a fascinating example where huge policy shifts drove change. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5036680/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>country</th> <th>year</th> <th>country_code</th> <th>record</th> <th>crop_land</th> <th>grazing_land</th> <th>forest_land</th> <th>fishing_ground</th> <th>built_up_land</th> <th>carbon</th> <th>total</th> <th>QScore</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Armenia</td> <td>1992</td> <td>1           </td> <td>AreaPerCap  </td> <td>0.140292 </td> <td>0.199546    </td> <td>0.097188051</td> <td>0.0368885     </td> <td>0.0293199    </td> <td>0     </td> <td>0.503235   </td> <td>3A    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Armenia</td> <td>1992</td> <td>1           </td> <td>AreaTotHA   </td> <td>483000   </td> <td>687000      </td> <td>334600     </td> <td>127000        </td> <td>100943       </td> <td>0     </td> <td>1.73254e+06</td> <td>3A    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Armenia</td> <td>1992</td> <td>1           </td> <td>BiocapPerCap</td> <td>0.159804 </td> <td>0.135261    </td> <td>0.084003213</td> <td>0.0137421     </td> <td>0.0333978    </td> <td>0     </td> <td>0.426209   </td> <td>3A    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (72183 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/NFA 2019 public_data.csv'\n",
    "ecoFootprint = Table.read_table(url, low_memory=False)\n",
    "ecoFootprint.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #2: Chronic Kidney Disease \n",
    "More information on columns at: https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease\n",
    "##### <font color='red'>** Note: This data is not available for a group project because it is part of a class demonstration of k nearest neighbor machine learning ** </font>\n",
    "See: [Class024](https://temple.2i2c.cloud/hub/user-redirect/lab/tree/datascience/Spring%202024/Class_Examples/Class024_knn%20kidney%20disease.ipynb)\n",
    "### Data Cleaning Issues:\n",
    "* There are missing values in some of the columns.\n",
    "\n",
    "### Possible Hypothesis to Test:\n",
    "This dataset is structured for machine learning to identify patients as positive or negative for chronic kidney disease. It would be intesting to campare the means of various columns for pos and neg patients.  Correlations are likely to exist as well. The data set is also a candidate for machine learning using k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>age</th> <th>bp</th> <th>sg</th> <th>al</th> <th>su</th> <th>rbc</th> <th>pc</th> <th>pcc</th> <th>ba</th> <th>bgr</th> <th>bu</th> <th>sc</th> <th>sod</th> <th>pot</th> <th>hemo</th> <th>pcv</th> <th>wc</th> <th>rc</th> <th>htn</th> <th>dm</th> <th>cad</th> <th>appet</th> <th>pe</th> <th>ane</th> <th>classification</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0   </td> <td>48  </td> <td>80  </td> <td>1.02</td> <td>1   </td> <td>0   </td> <td>nan   </td> <td>normal</td> <td>notpresent</td> <td>notpresent</td> <td>121 </td> <td>36  </td> <td>1.2 </td> <td>nan </td> <td>nan </td> <td>15.4</td> <td>44  </td> <td>7800</td> <td>5.2 </td> <td>yes </td> <td>yes </td> <td>no  </td> <td>good </td> <td>no  </td> <td>no  </td> <td>ckd           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>7   </td> <td>50  </td> <td>1.02</td> <td>4   </td> <td>0   </td> <td>nan   </td> <td>normal</td> <td>notpresent</td> <td>notpresent</td> <td>nan </td> <td>18  </td> <td>0.8 </td> <td>nan </td> <td>nan </td> <td>11.3</td> <td>38  </td> <td>6000</td> <td>nan </td> <td>no  </td> <td>no  </td> <td>no  </td> <td>good </td> <td>no  </td> <td>no  </td> <td>ckd           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>62  </td> <td>80  </td> <td>1.01</td> <td>2   </td> <td>3   </td> <td>normal</td> <td>normal</td> <td>notpresent</td> <td>notpresent</td> <td>423 </td> <td>53  </td> <td>1.8 </td> <td>nan </td> <td>nan </td> <td>9.6 </td> <td>31  </td> <td>7500</td> <td>nan </td> <td>no  </td> <td>yes </td> <td>no  </td> <td>poor </td> <td>no  </td> <td>yes </td> <td>ckd           </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (397 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/kidney_disease.csv'\n",
    "kidneyDisease = Table.read_table(url)\n",
    "kidneyDisease.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #3: Periodic Table \n",
    "\n",
    "<img src=\"data/xkcd_periodic_table.png\" width=\"600\">\n",
    "\n",
    "More information on columns: https://www.kaggle.com/datasets/berkayalan/chemical-periodic-table-elements?select=chemical_elements.csv  Of course, there are numerous references that discuss element groupings.\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "* The Discovery(Year) column includes \"ancient\" as a year.\n",
    "* Some columns (e.g. Boiling point) load as strings because there are commas at the thousands place. and would need to be converted to numbers.\n",
    "\n",
    "### Possible Hypothesis:\n",
    "Does boiling point correlate with atomic weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Atomic Number</th> <th>Name</th> <th>Atomic weight</th> <th>Symbol</th> <th>Melting Point (°C)</th> <th>Boiling Point (°C)</th> <th>Discovery(Year)</th> <th>Group*</th> <th>Electron configuration,,</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1            </td> <td>Hydrogen</td> <td>1.008        </td> <td>H     </td> <td>-259              </td> <td>-253              </td> <td>1776           </td> <td>1     </td> <td>1s1,,                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2            </td> <td>Helium  </td> <td>4.003        </td> <td>He    </td> <td>-272              </td> <td>-269              </td> <td>1895           </td> <td>18    </td> <td>1s2,,                   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3            </td> <td>Lithium </td> <td>6.941        </td> <td>Li    </td> <td>180               </td> <td>1,347             </td> <td>1817           </td> <td>1     </td> <td>[He] 2s1,               </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (106 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/chemical_elements.csv'\n",
    "ptdf = pd.read_csv(url, sep = ';')\n",
    "pt = Table.from_df(ptdf)\n",
    "pt.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #4: Wine Quality Dataset \n",
    "More information at https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wine quality dataset can be used to understand which chemical properties contribute to a higher quality wine.\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "Data set is clean\n",
    "\n",
    "### Possible Hypothesis to Test:\n",
    "Example hypothesis: Wines with higher acidity may have lower quality at present (test) but improve with aging [Wine Enthusiast](https://www.wineenthusiast.com/basics/advanced-studies/what-is-acidity-in-wine/#). One might also compare the properties of red versus white wines. Do any have significantly different means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>fixed acidity</th> <th>volatile acidity</th> <th>citric acid</th> <th>residual sugar</th> <th>chlorides</th> <th>free sulfur dioxide</th> <th>total sulfur dioxide</th> <th>density</th> <th>pH</th> <th>sulphates</th> <th>alcohol</th> <th>quality</th> <th>type</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>7            </td> <td>0.27            </td> <td>0.36       </td> <td>20.7          </td> <td>0.045    </td> <td>45                 </td> <td>170                 </td> <td>1.001  </td> <td>3   </td> <td>0.45     </td> <td>8.8    </td> <td>6      </td> <td>white</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6.3          </td> <td>0.3             </td> <td>0.34       </td> <td>1.6           </td> <td>0.049    </td> <td>14                 </td> <td>132                 </td> <td>0.994  </td> <td>3.3 </td> <td>0.49     </td> <td>9.5    </td> <td>6      </td> <td>white</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8.1          </td> <td>0.28            </td> <td>0.4        </td> <td>6.9           </td> <td>0.05     </td> <td>30                 </td> <td>97                  </td> <td>0.9951 </td> <td>3.26</td> <td>0.44     </td> <td>10.1   </td> <td>6      </td> <td>white</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (6494 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine = Table().read_table('data/winequality_redwhite.csv')\n",
    "wine.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #5: Air Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[From Kaggle:](https://www.kaggle.com/datasets/tawfikelmetwally/air-quality-dataset?resource=download)\n",
    "\n",
    "**Content**\n",
    "The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city.\n",
    "Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses.\n",
    "\n",
    "Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities.\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "* 0-Date (DD/MM/YYYY)\n",
    "* 1-Time (HH.MM.SS)\n",
    "* 2-True hourly averaged concentration CO in mg/m^3 (reference analyzer)\n",
    "* 3-PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)\n",
    "* 4-True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\n",
    "* 5-True hourly averaged Benzene concentration in microg/m^3 (reference analyzer)\n",
    "* 6-PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\n",
    "* 7-True hourly averaged NOx concentration in ppb (reference analyzer)\n",
    "* 8-PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)\n",
    "* 9-True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\n",
    "* 10-PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\n",
    "* 11-PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\n",
    "* 12-Temperature in Â°C\n",
    "* 13-Relative Humidity (%)\n",
    "* 14-AH Absolute Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Issues:\n",
    "There are missing values (nans). Working with time series data can be tricky using tables; look at Lab 04 for useful functions.\n",
    "\n",
    "### Possible Hypotheses to Test:\n",
    "\n",
    "One could test whether there is a significant difference between Nitrous Oxide levels in the summer vs winter months. Exploring correlations beteen different contaminants would also be interesting. This is a rich data set, so there are many possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Date</th> <th>Time</th> <th>CO(GT)</th> <th>PT08.S1(CO)</th> <th>NMHC(GT)</th> <th>C6H6(GT)</th> <th>PT08.S2(NMHC)</th> <th>NOx(GT)</th> <th>PT08.S3(NOx)</th> <th>NO2(GT)</th> <th>PT08.S4(NO2)</th> <th>PT08.S5(O3)</th> <th>T</th> <th>RH</th> <th>AH</th> <th>Unnamed: 15</th> <th>Unnamed: 16</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>10/03/2004</td> <td>18:00:00</td> <td>2.6   </td> <td>1360       </td> <td>150     </td> <td>11.9    </td> <td>1046         </td> <td>166    </td> <td>1056        </td> <td>113    </td> <td>1692        </td> <td>1268       </td> <td>13.6</td> <td>48.9</td> <td>0.7578</td> <td>nan        </td> <td>nan        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>10/03/2004</td> <td>19:00:00</td> <td>2     </td> <td>1292       </td> <td>112     </td> <td>9.4     </td> <td>955          </td> <td>103    </td> <td>1174        </td> <td>92     </td> <td>1559        </td> <td>972        </td> <td>13.3</td> <td>47.7</td> <td>0.7255</td> <td>nan        </td> <td>nan        </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>10/03/2004</td> <td>20:00:00</td> <td>2.2   </td> <td>1402       </td> <td>88      </td> <td>9       </td> <td>939          </td> <td>131    </td> <td>1140        </td> <td>114    </td> <td>1555        </td> <td>1074       </td> <td>11.9</td> <td>54  </td> <td>0.7502</td> <td>nan        </td> <td>nan        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (9468 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/Air Quality.csv'\n",
    "air = Table.read_table(url)\n",
    "air.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #6:  Earthquakes in the East Coast of the US\n",
    "The east coast of the US does not have nearly as many earthquakes as California, but as we experienced this semester they do happen! The earthquake data provided here were extracted for the region shown on the map below for the last century, from 1924 to 2024 (of course the monitoring of early earthquake is incomplete).\n",
    "More information: https://earthquake.usgs.gov/earthquakes/map\n",
    "\n",
    "<img src=\"data/earthquake_extraction_region.jpeg\">\n",
    "\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "\n",
    "There are missing values in many files. Infomation such as the state name will have to be extracted from the \"place\" column.\n",
    "\n",
    "### Possible Hypothesis:\n",
    "One might compare earthquakes in Pennsylvania and New York to see if there is a significant difference in the mean earthquake magnitude by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>time</th> <th>latitude</th> <th>longitude</th> <th>depth</th> <th>mag</th> <th>magType</th> <th>nst</th> <th>gap</th> <th>dmin</th> <th>rms</th> <th>net</th> <th>id</th> <th>updated</th> <th>place</th> <th>type</th> <th>horizontalError</th> <th>depthError</th> <th>magError</th> <th>magNst</th> <th>status</th> <th>locationSource</th> <th>magSource</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1925-10-09T13:55:00.000Z</td> <td>43.7    </td> <td>-71.1    </td> <td>nan  </td> <td>4   </td> <td>fa     </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>ushis</td> <td>ushis732</td> <td>2018-06-04T20:43:44.000Z</td> <td>2 km NE of Ossipee, New Hampshire</td> <td>earthquake</td> <td>nan            </td> <td>nan       </td> <td>nan     </td> <td>nan   </td> <td>reviewed</td> <td>ushis         </td> <td>sc       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1926-11-05T16:53:00.000Z</td> <td>39.1    </td> <td>-82.1    </td> <td>nan  </td> <td>3.8 </td> <td>fa     </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>ushis</td> <td>ushis753</td> <td>2018-06-04T20:43:44.000Z</td> <td>6 km NNE of Rutland, Ohio        </td> <td>earthquake</td> <td>nan            </td> <td>nan       </td> <td>nan     </td> <td>nan   </td> <td>reviewed</td> <td>ushis         </td> <td>sc       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1928-03-18T15:20:00.000Z</td> <td>44.5    </td> <td>-74.3    </td> <td>nan  </td> <td>4.1 </td> <td>ml     </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>nan </td> <td>ushis</td> <td>ushis781</td> <td>2018-06-04T20:43:44.000Z</td> <td>7 km NNW of Paul Smiths, New York</td> <td>earthquake</td> <td>nan            </td> <td>nan       </td> <td>nan     </td> <td>nan   </td> <td>reviewed</td> <td>ushis         </td> <td>epb      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1503 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/east_coast_earthquakes.csv'\n",
    "eq = Table.read_table(url)\n",
    "eq.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #7: Steam Gage data for the Pennypack Creek in Philadelphia\n",
    "The US Geological Survey has gages on many US streams that collect data data continuously. The Pennypack Creek runs through Philadelphia.\n",
    "See this website: https://waterdata.usgs.gov/monitoring-location/01467042/#parameterCode=00065&period=P7D&showMedian=true\n",
    "\n",
    "### Possible relationship to explore: \n",
    "\n",
    "Tubidity (sediment in water) and Discharge (stream flow rate)\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "\n",
    "Working with time series data can be tricky using tables; look at Lab 04 for useful functions.\n",
    "\n",
    "#### Column Headers in the data set\n",
    "```\n",
    "# Data provided for site 01467042\n",
    "#    TS_ID       Parameter Description\n",
    "#    121360      00010     Temperature, water, degrees Celsius\n",
    "#    121357      00060     Discharge, cubic feet per second\n",
    "#    121358      00065     Gage height, feet\n",
    "#    121361      00095     Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius\n",
    "#    121364      00300     Dissolved oxygen, water, unfiltered, milligrams per liter\n",
    "#    121365      00301     Dissolved oxygen, water, unfiltered, percent of saturation\n",
    "#    121362      00400     pH, water, unfiltered, field, standard units\n",
    "#    277154      63680     Turbidity, water, unfiltered, monochrome near infra-red LED light, 780-900 nm, detection angle 90 +-2.5 degrees, formazin nephelometric units (FNU)\n",
    "#\n",
    "# Data-value qualification codes included in this output:\n",
    "#     P  Provisional data subject to revision.\n",
    "#     <  Actual value is known to be less than reported value.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>agency_cd</th> <th>site_no</th> <th>datetime</th> <th>tz_cd</th> <th>121360_00010</th> <th>121360_00010_cd</th> <th>121357_00060</th> <th>121357_00060_cd</th> <th>121358_00065</th> <th>121358_00065_cd</th> <th>121361_00095</th> <th>121361_00095_cd</th> <th>121364_00300</th> <th>121364_00300_cd</th> <th>121365_00301</th> <th>121365_00301_cd</th> <th>121362_00400</th> <th>121362_00400_cd</th> <th>277154_63680</th> <th>277154_63680_cd</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>USGS     </td> <td>1467042</td> <td>2023-09-01 00:00</td> <td>EDT  </td> <td>21.4        </td> <td>P              </td> <td>23.5        </td> <td>P              </td> <td>3.21        </td> <td>P              </td> <td>667         </td> <td>P              </td> <td>8.1         </td> <td>P              </td> <td>92          </td> <td>P              </td> <td>7.7         </td> <td>P              </td> <td>0.3         </td> <td>P:<            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>USGS     </td> <td>1467042</td> <td>2023-09-01 00:15</td> <td>EDT  </td> <td>21.3        </td> <td>P              </td> <td>24.7        </td> <td>P              </td> <td>3.22        </td> <td>P              </td> <td>668         </td> <td>P              </td> <td>8.1         </td> <td>P              </td> <td>92          </td> <td>P              </td> <td>7.6         </td> <td>P              </td> <td>0.3         </td> <td>P:<            </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>USGS     </td> <td>1467042</td> <td>2023-09-01 00:30</td> <td>EDT  </td> <td>21.2        </td> <td>P              </td> <td>23.5        </td> <td>P              </td> <td>3.21        </td> <td>P              </td> <td>668         </td> <td>P              </td> <td>8           </td> <td>P              </td> <td>90          </td> <td>P              </td> <td>7.6         </td> <td>P              </td> <td>0.3         </td> <td>P              </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (6819 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/penny_pack.csv'\n",
    "pp = Table.read_table(url)\n",
    "pp.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #8:  Weather Data\n",
    "Data from a Weather Underground station in the South Kensington neighborhood of Philadelphia\n",
    "South Kensington - KPAPHILA131: https://www.wunderground.com/dashboard/pws/KPAPHILA131\n",
    "\n",
    "The data are hourly from December 2019 to January 2021.\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "\n",
    "Working with time series data can be tricky using tables; look at Lab 04 for useful functions. To compare data by month requires parsing the date information.\n",
    "\n",
    "### Possible Hypotheses\n",
    "There are many interesting relationships to explore, such as between barometeric pressure trends and precipitation, or seasonal differences in rainfall, temperature, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>stationID</th> <th>tz</th> <th>obsTimeUtc</th> <th>obsTimeLocal</th> <th>epoch</th> <th>lat</th> <th>lon</th> <th>solarRadiationHigh</th> <th>uvHigh</th> <th>winddirAvg</th> <th>humidityHigh</th> <th>humidityLow</th> <th>humidityAvg</th> <th>qcStatus</th> <th>metric.tempHigh</th> <th>metric.tempLow</th> <th>metric.tempAvg</th> <th>metric.windspeedHigh</th> <th>metric.windspeedLow</th> <th>metric.windspeedAvg</th> <th>metric.windgustHigh</th> <th>metric.windgustLow</th> <th>metric.windgustAvg</th> <th>metric.dewptHigh</th> <th>metric.dewptLow</th> <th>metric.dewptAvg</th> <th>metric.windchillHigh</th> <th>metric.windchillLow</th> <th>metric.windchillAvg</th> <th>metric.heatindexHigh</th> <th>metric.heatindexLow</th> <th>metric.heatindexAvg</th> <th>metric.pressureMax</th> <th>metric.pressureMin</th> <th>metric.pressureTrend</th> <th>metric.precipRate</th> <th>metric.precipTotal</th> <th>dateTimeUtc</th> <th>obsTimeEST</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>KPAPHILA131</td> <td>America/New_York</td> <td>2019-12-17T05:59:16Z</td> <td>2019-12-17 00:59:16</td> <td>1576562356</td> <td>39.9712</td> <td>-75.1362</td> <td>0                 </td> <td>0     </td> <td>62        </td> <td>89          </td> <td>88         </td> <td>88.6       </td> <td>1       </td> <td>1.1            </td> <td>1             </td> <td>1             </td> <td>13                  </td> <td>0                  </td> <td>5.7                </td> <td>20.2               </td> <td>0                 </td> <td>8                 </td> <td>-0.5            </td> <td>-0.8           </td> <td>-0.7           </td> <td>1.1                 </td> <td>-2.8               </td> <td>-0.4               </td> <td>1.1                 </td> <td>1                  </td> <td>1                  </td> <td>1013.55           </td> <td>1012.19           </td> <td>-0.69               </td> <td>5.33             </td> <td>5.33              </td> <td>2019-12-17 05:59:16+00:00</td> <td>2019-12-17 00:59:16</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>KPAPHILA131</td> <td>America/New_York</td> <td>2019-12-17T06:59:16Z</td> <td>2019-12-17 01:59:16</td> <td>1576565956</td> <td>39.9712</td> <td>-75.1362</td> <td>0                 </td> <td>0     </td> <td>70        </td> <td>90          </td> <td>89         </td> <td>89.8       </td> <td>1       </td> <td>1.2            </td> <td>1.1           </td> <td>1.2           </td> <td>22.7                </td> <td>0                  </td> <td>6.4                </td> <td>28.1               </td> <td>0                 </td> <td>9.2               </td> <td>-0.3            </td> <td>-0.5           </td> <td>-0.3           </td> <td>1.2                 </td> <td>-4                 </td> <td>-0.4               </td> <td>1.2                 </td> <td>1.1                </td> <td>1.2                </td> <td>1012.19           </td> <td>1010.5            </td> <td>-1.38               </td> <td>4.32             </td> <td>9.65              </td> <td>2019-12-17 06:59:16+00:00</td> <td>2019-12-17 01:59:16</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>KPAPHILA131</td> <td>America/New_York</td> <td>2019-12-17T07:59:16Z</td> <td>2019-12-17 02:59:16</td> <td>1576569556</td> <td>39.9712</td> <td>-75.1362</td> <td>0                 </td> <td>0     </td> <td>70        </td> <td>91          </td> <td>90         </td> <td>90.5       </td> <td>1       </td> <td>1.4            </td> <td>1.2           </td> <td>1.3           </td> <td>19.1                </td> <td>0                  </td> <td>6.9                </td> <td>28.1               </td> <td>0                 </td> <td>9.9               </td> <td>0.1             </td> <td>-0.3           </td> <td>-0.1           </td> <td>1.4                 </td> <td>-3.3               </td> <td>-0.4               </td> <td>1.4                 </td> <td>1.2                </td> <td>1.3                </td> <td>1011.18           </td> <td>1009.48           </td> <td>-1.38               </td> <td>1.78             </td> <td>11.43             </td> <td>2019-12-17 07:59:16+00:00</td> <td>2019-12-17 02:59:16</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (16313 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/KPAPHILA131_20191217_to_20211119.csv'\n",
    "weather = Table.read_table(url)\n",
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #9:  Fetal Health \n",
    "Kaggle Dataset: https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification\n",
    "\n",
    "Reduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress.\n",
    "The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce under‑5 mortality to at least as low as 25 per 1,000 live births.\n",
    "\n",
    "Parallel to notion of child mortality is of course maternal mortality, which accounts for 295 000 deaths during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented.\n",
    "\n",
    "In light of what was mentioned above, Cardiotocograms (CTGs) are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.\n",
    "\n",
    "Data\n",
    "This dataset contains 2126 records of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into 3 classes:\n",
    "\n",
    "fetal_health\n",
    "* Normal (1)\n",
    "* Suspect (2)\n",
    "* Pathological (3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Issues:\n",
    "\n",
    "The data appear to be clean. Need to research the features obtained from Cardiotocograms.\n",
    "\n",
    "### Possible Hypotheses:\n",
    "Apart from explored correlations, this dataset would be an excellent one to try k-means prediction of fetal health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>baseline value</th> <th>accelerations</th> <th>fetal_movement</th> <th>uterine_contractions</th> <th>light_decelerations</th> <th>severe_decelerations</th> <th>prolongued_decelerations</th> <th>abnormal_short_term_variability</th> <th>mean_value_of_short_term_variability</th> <th>percentage_of_time_with_abnormal_long_term_variability</th> <th>mean_value_of_long_term_variability</th> <th>histogram_width</th> <th>histogram_min</th> <th>histogram_max</th> <th>histogram_number_of_peaks</th> <th>histogram_number_of_zeroes</th> <th>histogram_mode</th> <th>histogram_mean</th> <th>histogram_median</th> <th>histogram_variance</th> <th>histogram_tendency</th> <th>fetal_health</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>120           </td> <td>0            </td> <td>0             </td> <td>0                   </td> <td>0                  </td> <td>0                   </td> <td>0                       </td> <td>73                             </td> <td>0.5                                 </td> <td>43                                                    </td> <td>2.4                                </td> <td>64             </td> <td>62           </td> <td>126          </td> <td>2                        </td> <td>0                         </td> <td>120           </td> <td>137           </td> <td>121             </td> <td>73                </td> <td>1                 </td> <td>2           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>132           </td> <td>0.006        </td> <td>0             </td> <td>0.006               </td> <td>0.003              </td> <td>0                   </td> <td>0                       </td> <td>17                             </td> <td>2.1                                 </td> <td>0                                                     </td> <td>10.4                               </td> <td>130            </td> <td>68           </td> <td>198          </td> <td>6                        </td> <td>1                         </td> <td>141           </td> <td>136           </td> <td>140             </td> <td>12                </td> <td>0                 </td> <td>1           </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>133           </td> <td>0.003        </td> <td>0             </td> <td>0.008               </td> <td>0.003              </td> <td>0                   </td> <td>0                       </td> <td>16                             </td> <td>2.1                                 </td> <td>0                                                     </td> <td>13.4                               </td> <td>130            </td> <td>68           </td> <td>198          </td> <td>5                        </td> <td>1                         </td> <td>141           </td> <td>135           </td> <td>138             </td> <td>13                </td> <td>0                 </td> <td>1           </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (2123 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = \"data/fetal_health.csv\"\n",
    "fetal = Table().read_table(filename)\n",
    "fetal.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>zip</th> <th>city</th> <th>county</th> <th>pop</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>19120</td> <td>Philadelphia</td> <td>Philadelphia</td> <td>74060</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19124</td> <td>Philadelphia</td> <td>Philadelphia</td> <td>70304</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19111</td> <td>Philadelphia</td> <td>Philadelphia</td> <td>68113</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (45 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## might be also useful to have population for looking at Philly Vaccination Rates\n",
    "url = \"https://raw.githubusercontent.com/DataScienceTempleFirst/code-cod/main/PA_zip_pop.csv\"\n",
    "paPop = Table.read_table(url)\n",
    "paPop.sort(\"pop\",descending=True)\n",
    "paPop.where('county','Philadelphia').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #10: Diabetes Prediction\n",
    "This data set is from Kaggle. https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset\n",
    "\n",
    "**Description:**\n",
    "\n",
    "\"The Diabetes prediction dataset is a collection of medical and demographic data from patients, along with their diabetes status (positive or negative). The data includes features such as age, gender, body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level. This dataset can be used to build machine learning models to predict diabetes in patients based on their medical history and demographic information. This can be useful for healthcare professionals in identifying patients who may be at risk of developing diabetes and in developing personalized treatment plans. Additionally, the dataset can be used by researchers to explore the relationships between various medical and demographic factors and the likelihood of developing diabetes.\"\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "\n",
    "While there are no missing values, the gender and smoking history columns needs to be converted to a numbers to model.\n",
    "\n",
    "### Possible Hypotheses:\n",
    "This data set is a good candidate for k-mean clustering to predict the whether a patient has diabetes. One could also explore correlation between fields, look at differences by gender, smoking history, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>gender</th> <th>age</th> <th>hypertension</th> <th>heart_disease</th> <th>smoking_history</th> <th>bmi</th> <th>HbA1c_level</th> <th>blood_glucose_level</th> <th>diabetes</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Female</td> <td>80  </td> <td>0           </td> <td>1            </td> <td>never          </td> <td>25.19</td> <td>6.6        </td> <td>140                </td> <td>0       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Female</td> <td>54  </td> <td>0           </td> <td>0            </td> <td>No Info        </td> <td>27.32</td> <td>6.6        </td> <td>80                 </td> <td>0       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Male  </td> <td>28  </td> <td>0           </td> <td>0            </td> <td>never          </td> <td>27.32</td> <td>5.7        </td> <td>158                </td> <td>0       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (99997 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/diabetes_prediction_dataset.csv'\n",
    "diabetes = Table.read_table(url)\n",
    "diabetes.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>statistic</th> <th>gender</th> <th>age</th> <th>hypertension</th> <th>heart_disease</th> <th>smoking_history</th> <th>bmi</th> <th>HbA1c_level</th> <th>blood_glucose_level</th> <th>diabetes</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>min      </td> <td>Female</td> <td>0.08       </td> <td>0           </td> <td>0            </td> <td>No Info        </td> <td>10.01      </td> <td>3.5        </td> <td>80                 </td> <td>0       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>max      </td> <td>Other </td> <td>80         </td> <td>1           </td> <td>1            </td> <td>not current    </td> <td>95.69      </td> <td>9          </td> <td>300                </td> <td>1       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>median   </td> <td>      </td> <td>43         </td> <td>0           </td> <td>0            </td> <td>               </td> <td>27.32      </td> <td>5.8        </td> <td>140                </td> <td>0       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>sum      </td> <td>      </td> <td>4.18859e+06</td> <td>7485        </td> <td>3942         </td> <td>               </td> <td>2.73208e+06</td> <td>552751     </td> <td>1.38058e+07        </td> <td>8500    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "statistic | gender | age         | hypertension | heart_disease | smoking_history | bmi         | HbA1c_level | blood_glucose_level | diabetes\n",
       "min       | Female | 0.08        | 0            | 0             | No Info         | 10.01       | 3.5         | 80                  | 0\n",
       "max       | Other  | 80          | 1            | 1             | not current     | 95.69       | 9           | 300                 | 1\n",
       "median    |        | 43          | 0            | 0             |                 | 27.32       | 5.8         | 140                 | 0\n",
       "sum       |        | 4.18859e+06 | 7485         | 3942          |                 | 2.73208e+06 | 552751      | 1.38058e+07         | 8500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Info', 'current', 'ever', 'former', 'never', 'not current'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(diabetes['smoking_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #11: Philadelphia Open Data School Graduation Rates\n",
    "This longitudinal open data file includes information about the graduation rates for schools broken out by: graduation rate type (four-year, five-year, or six-year), demographic category (EL status, IEP status, Economically Disadvantaged Status, Gender, or Ethnicity), and ninth-grade cohort. Students are attributed to the last school at which they actively attended in the respective graduation window, which ends on September 30 each year. Students are classified as EL, as having an IEP, and/or economically disadvantaged if they were designated as such at any point during their high school career.\n",
    "see: https://www.philasd.org/performance/programsservices/open-data/school-performance/#school_graduation_rates \n",
    "see also: https://www.philasd.org/research/wp-content/uploads/sites/90/2020/05/graduation-rate-definitions-and-trends-may-2020.pdf\n",
    "\n",
    "### Data Cleaning Issue:\n",
    "Some of the fields have mixed numerical and text data (e.g., num, score), with the code \"s\" where a score was not calculated.\n",
    "\n",
    "### Possible Hypotheses\n",
    "Many possibilities. One could look at whether there is a statistically significance difference in scores between two schools, investigate trends over time, or look at differenct groups an subgroups. Keep in mind that this a limited data set covering a socially sensitive topic, so do not draw overly broad conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>cohort</th> <th>schoolid_ulcs</th> <th>schoolname</th> <th>sector</th> <th>rate_type</th> <th>group</th> <th>subgroup</th> <th>denom</th> <th>num</th> <th>score</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2010-2011</td> <td>1010         </td> <td>John Bartram High School</td> <td>District</td> <td>4-Year Graduation Rate</td> <td>All Students              </td> <td>All Students                  </td> <td>281  </td> <td>203 </td> <td>72.24</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-2011</td> <td>1010         </td> <td>John Bartram High School</td> <td>District</td> <td>4-Year Graduation Rate</td> <td>Economically Disadvantaged</td> <td>Economically Disadvantaged    </td> <td>211  </td> <td>153 </td> <td>72.51</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-2011</td> <td>1010         </td> <td>John Bartram High School</td> <td>District</td> <td>4-Year Graduation Rate</td> <td>Economically Disadvantaged</td> <td>Not Economically Disadvantaged</td> <td>70   </td> <td>50  </td> <td>71.43</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (23018 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://cdn.philasd.org/offices/performance/Open_Data/School_Performance/Graduation_Rates/SDP_Graduation_Rates_School_S_2022-05-23.csv\"\n",
    "grad = Table.read_table(url)\n",
    "grad.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #12: Jeopardy\n",
    "see: https://www.jeopardy.com\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "Multiple table to join. Some fields have missing values.\n",
    "\n",
    "### Possible Hypothesis to Test:\n",
    "Do returning champions score better? Does seating position matter? There are many imaginative possibilities to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>game_id</th> <th>season</th> <th>position</th> <th>dj_score</th> <th>wager</th> <th>correct</th> <th>coryat_score</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>5635   </td> <td>33    </td> <td>returning_champion</td> <td>10000   </td> <td>3001 </td> <td>1      </td> <td>11000       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5635   </td> <td>33    </td> <td>middle            </td> <td>12000   </td> <td>12000</td> <td>0      </td> <td>12000       </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5635   </td> <td>33    </td> <td>right             </td> <td>13000   </td> <td>11001</td> <td>0      </td> <td>15200       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (12009 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contestant = \"https://raw.githubusercontent.com/anuparna/jeopardy/master/dataset/contestants.csv\"\n",
    "locations =  \"https://raw.githubusercontent.com/anuparna/jeopardy/master/dataset/locations.csv\"\n",
    "results =  \"https://raw.githubusercontent.com/anuparna/jeopardy/master/dataset/final_results.csv\"\n",
    "loc = Table.read_table(locations)\n",
    "contest = Table.read_table(contestant)\n",
    "outcome = Table.read_table(results)\n",
    "outcome.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #13: Crime Data for Philadelphia\n",
    "The data came from OpenDataPhilly: https://opendataphilly.org/datasets/crime-incidents\n",
    "Reported incidents cover the full year of 2023.\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "To extract months you would need to parse the date data. Working with time series data can be tricky using tables; look at Lab 04 for useful functions. To compare data by month requires parsing the date information.\n",
    "\n",
    "### Possible Hypotheses:\n",
    "Possible correlation: type of crime and time of day. Could look at where at particular type of crime occurs more frequency at particular time of day or whether the number of crimes is significantly different in different months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>the_geom</th> <th>cartodb_id</th> <th>the_geom_webmercator</th> <th>objectid</th> <th>dc_dist</th> <th>psa</th> <th>dispatch_date_time</th> <th>dispatch_date</th> <th>dispatch_time</th> <th>hour</th> <th>dc_key</th> <th>location_block</th> <th>ucr_general</th> <th>text_general_code</th> <th>point_x</th> <th>point_y</th> <th>lat</th> <th>lng</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0101000020E6100000A51C8299A5C752C006342AD3DCFF4340</td> <td>2         </td> <td>0101000020110F0000F80DE2A145E65FC1E5EC7592BE8F5241</td> <td>114     </td> <td>25     </td> <td>3   </td> <td>2023-03-11 17:12:00+00</td> <td>2023-03-11   </td> <td>12:12:00     </td> <td>12  </td> <td>2.02325e+11</td> <td>3300 BLOCK HARTVILLE ST  </td> <td>300        </td> <td>Robbery No Firearm</td> <td>-75.1195</td> <td>39.9989</td> <td>39.9989</td> <td>-75.1195</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0101000020E6100000F9245E3B64CC52C0B7195D940FF64340</td> <td>4         </td> <td>0101000020110F00000426B7CE54EE5FC1C5E06D37E2845241</td> <td>116     </td> <td>1      </td> <td>1   </td> <td>2023-03-11 18:31:00+00</td> <td>2023-03-11   </td> <td>13:31:00     </td> <td>13  </td> <td>2.02301e+11</td> <td>2400 BLOCK S 28TH ST     </td> <td>600        </td> <td>Theft from Vehicle</td> <td>-75.1936</td> <td>39.9224</td> <td>39.9224</td> <td>-75.1936</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0101000020E6100000118A52E7F6C052C0CFF41263190C4440</td> <td>7         </td> <td>0101000020110F00006728CED7EBDA5FC169DB64F8519D5241</td> <td>119     </td> <td>8      </td> <td>2   </td> <td>2023-03-11 22:13:00+00</td> <td>2023-03-11   </td> <td>17:13:00     </td> <td>17  </td> <td>2.02308e+11</td> <td>9800 BLOCK Roosevelt Blvd</td> <td>600        </td> <td>Thefts            </td> <td>-75.0151</td> <td>40.0945</td> <td>40.0945</td> <td>-75.0151</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (169014 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'data/Philly_crime_2023.csv'\n",
    "crime = Table.read_table(url)\n",
    "crime.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #14: Global Sustainable Energy Production\n",
    "Data set taken from Kaggle:\n",
    "\n",
    "\"Uncover this dataset showcasing sustainable energy indicators and other useful factors across all countries from 2000 to 2020. Dive into vital aspects such as electricity access, renewable energy, carbon emissions, energy intensity, Financial flows, and economic growth. Compare nations, track progress towards Sustainable Development Goal 7, and gain profound insights into global energy consumption patterns over time.\"\n",
    "\n",
    "Metadata: https://www.kaggle.com/datasets/anshtanwar/global-data-on-sustainable-energy\n",
    "\n",
    "### Data Cleaning Issues:\n",
    "Field names are overly long. Some fields have missing values.\n",
    "\n",
    "### Possible Hypotheses:\n",
    "Can investigate trends over time, differences in means between countries, correlation between fields -- many possibilities! For example, one could look for differences between the energy habits of richer (gdp_per_capita) and poorer nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Entity</th> <th>Year</th> <th>Access to electricity (% of population)</th> <th>Access to clean fuels for cooking</th> <th>Renewable-electricity-generating-capacity-per-capita</th> <th>Financial flows to developing countries (US $)</th> <th>Renewable energy share in the total final energy consumption (%)</th> <th>Electricity from fossil fuels (TWh)</th> <th>Electricity from nuclear (TWh)</th> <th>Electricity from renewables (TWh)</th> <th>Low-carbon electricity (% electricity)</th> <th>Primary energy consumption per capita (kWh/person)</th> <th>Energy intensity level of primary energy (MJ/$2017 PPP GDP)</th> <th>Value_co2_emissions_kt_by_country</th> <th>Renewables (% equivalent primary energy)</th> <th>gdp_growth</th> <th>gdp_per_capita</th> <th>Density\\n(P/Km2)</th> <th>Land Area(Km2)</th> <th>Latitude</th> <th>Longitude</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Afghanistan</td> <td>2000</td> <td>1.61359                                </td> <td>6.2                              </td> <td>9.22                                                </td> <td>20000                                         </td> <td>44.99                                                           </td> <td>0.16                               </td> <td>0                             </td> <td>0.31                             </td> <td>65.9574                               </td> <td>302.595                                           </td> <td>1.64                                                       </td> <td>760                              </td> <td>nan                                     </td> <td>nan       </td> <td>nan           </td> <td>60              </td> <td>652230        </td> <td>33.9391 </td> <td>67.71    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Afghanistan</td> <td>2001</td> <td>4.07457                                </td> <td>7.2                              </td> <td>8.86                                                </td> <td>130000                                        </td> <td>45.6                                                            </td> <td>0.09                               </td> <td>0                             </td> <td>0.5                              </td> <td>84.7458                               </td> <td>236.892                                           </td> <td>1.74                                                       </td> <td>730                              </td> <td>nan                                     </td> <td>nan       </td> <td>nan           </td> <td>60              </td> <td>652230        </td> <td>33.9391 </td> <td>67.71    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Afghanistan</td> <td>2002</td> <td>9.40916                                </td> <td>8.2                              </td> <td>8.47                                                </td> <td>3.95e+06                                      </td> <td>37.83                                                           </td> <td>0.13                               </td> <td>0                             </td> <td>0.56                             </td> <td>81.1594                               </td> <td>210.862                                           </td> <td>1.4                                                        </td> <td>1030                             </td> <td>nan                                     </td> <td>nan       </td> <td>179.427       </td> <td>60              </td> <td>652230        </td> <td>33.9391 </td> <td>67.71    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (3646 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = \"data/global-data-on-sustainable-energy.csv\"\n",
    "energy = Table.read_table(filename)\n",
    "energy.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Set #15: Motor Vehicle Crash Data for Staten Island in 2023\n",
    "\n",
    "This data set came from Data.gov. The accident data file for New York city is huge, so it has been trimmed to just Staten Island in 2023.\n",
    "\n",
    "https://catalog.data.gov/dataset/motor-vehicle-collisions-crashes\n",
    "\n",
    "\"The Motor Vehicle Collisions crash table contains details on the crash event. Each row represents a crash event. The Motor Vehicle Collisions data tables contain information from all police reported motor vehicle collisions in NYC. The police report (MV104-AN) is required to be filled out for collisions where someone is injured or killed, or where there is at least $1000 worth of damage (https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/ny_overlay_mv-104an_rev05_2004.pdf). It should be noted that the data is preliminary and subject to change when the MV-104AN forms are amended based on revised crash details.For the most accurate, up to date statistics on traffic fatalities, please refer to the NYPD Motor Vehicle Collisions page (updated weekly) or Vision Zero View (updated monthly).\"\n",
    "\n",
    "### Data Cleaning Issues\n",
    "\n",
    "Some fields have missing values. May need to parse dates.\n",
    "\n",
    "### Possible Hypotheses\n",
    "Such a large data set opens up many possibilities. Compare percent of accidents resulting in fatalities by vechicle type? How about in two-vehicle accidents? Are certain months statistically more likely to have accidents? Certain zipcodes (may need to look for populations data to convert to per capita)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Unnamed: 0</th> <th>CRASH DATE</th> <th>CRASH TIME</th> <th>BOROUGH</th> <th>ZIP CODE</th> <th>LATITUDE</th> <th>LONGITUDE</th> <th>LOCATION</th> <th>ON STREET NAME</th> <th>CROSS STREET NAME</th> <th>OFF STREET NAME</th> <th>NUMBER OF PERSONS INJURED</th> <th>NUMBER OF PERSONS KILLED</th> <th>NUMBER OF PEDESTRIANS INJURED</th> <th>NUMBER OF PEDESTRIANS KILLED</th> <th>NUMBER OF CYCLIST INJURED</th> <th>NUMBER OF CYCLIST KILLED</th> <th>NUMBER OF MOTORIST INJURED</th> <th>NUMBER OF MOTORIST KILLED</th> <th>CONTRIBUTING FACTOR VEHICLE 1</th> <th>CONTRIBUTING FACTOR VEHICLE 2</th> <th>CONTRIBUTING FACTOR VEHICLE 3</th> <th>CONTRIBUTING FACTOR VEHICLE 4</th> <th>CONTRIBUTING FACTOR VEHICLE 5</th> <th>COLLISION_ID</th> <th>VEHICLE TYPE CODE 1</th> <th>VEHICLE TYPE CODE 2</th> <th>VEHICLE TYPE CODE 3</th> <th>VEHICLE TYPE CODE 4</th> <th>VEHICLE TYPE CODE 5</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>24        </td> <td>12/13/2021</td> <td>17:40     </td> <td>STATEN ISLAND</td> <td>10301   </td> <td>40.6317 </td> <td>-74.0876 </td> <td>(40.63165, -74.08762) </td> <td>VICTORY BOULEVARD</td> <td>WOODSTOCK AVENUE </td> <td>nan                 </td> <td>1                        </td> <td>0                       </td> <td>0                            </td> <td>0                           </td> <td>0                        </td> <td>0                       </td> <td>1                         </td> <td>0                        </td> <td>Unspecified                   </td> <td>Unspecified                  </td> <td>nan                          </td> <td>nan                          </td> <td>nan                          </td> <td>4487001     </td> <td>Sedan              </td> <td>Sedan              </td> <td>nan                </td> <td>nan                </td> <td>nan                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>83        </td> <td>12/08/2021</td> <td>22:37     </td> <td>STATEN ISLAND</td> <td>10314   </td> <td>40.6212 </td> <td>-74.1239 </td> <td>(40.62121, -74.12385) </td> <td>nan              </td> <td>nan              </td> <td>288       MANOR ROAD</td> <td>0                        </td> <td>0                       </td> <td>0                            </td> <td>0                           </td> <td>0                        </td> <td>0                       </td> <td>0                         </td> <td>0                        </td> <td>Pavement Slippery             </td> <td>nan                          </td> <td>nan                          </td> <td>nan                          </td> <td>nan                          </td> <td>4484906     </td> <td>Sedan              </td> <td>nan                </td> <td>nan                </td> <td>nan                </td> <td>nan                </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>94        </td> <td>03/26/2022</td> <td>14:00     </td> <td>STATEN ISLAND</td> <td>10301   </td> <td>40.6378 </td> <td>-74.0819 </td> <td>(40.637833, -74.08193)</td> <td>CORSON AVENUE    </td> <td>WESTERVELT AVENUE</td> <td>nan                 </td> <td>0                        </td> <td>0                       </td> <td>0                            </td> <td>0                           </td> <td>0                        </td> <td>0                       </td> <td>0                         </td> <td>0                        </td> <td>Driver Inattention/Distraction</td> <td>Unspecified                  </td> <td>nan                          </td> <td>nan                          </td> <td>nan                          </td> <td>4513697     </td> <td>Sedan              </td> <td>Sedan              </td> <td>nan                </td> <td>nan                </td> <td>nan                </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (60106 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'data/StatenIsland_crash_data_2023.csv'\n",
    "crash = Table.read_table(filename)\n",
    "crash.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
